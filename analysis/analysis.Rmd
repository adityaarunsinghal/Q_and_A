---
title: "Questions and Answers in Dialogue"
output: html_notebook
---

# Imports 

```{r}
library(tidyverse)

library(GGally)
library(coda)
library(knitr)
library(gridExtra)
library(boot)

estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}

HPDhi<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}

HPDlo<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
options("scipen"=10) 
# opts_knit$set(root.dir = '')
# setwd("/Users/rxdh/Box Sync/stanford/research/goodman/q&a/MultiExperiment2/")

```

Experiment data analysis
--------------------------

Start by setting up exclusion criteria for participants who don't speak english or didn't complete the full task.

```{r}
subjInfo = read_csv("../data/compiled-subject_information.csv")

mturk = read_csv("../data/compiled-mturk.csv") %>%
  mutate(gameid = Answer.id) %>%
  select(workerid, gameid)

rawAggregated = read_csv("../data/compiled-trials_clean.csv") %>%
  right_join(mturk, by = 'workerid') %>%
  right_join(subjInfo, by = 'workerid')
```

Filter out participants who didn't complete all 12 trials, had missing data (i.e. didn't answer for some subset of trials), or didn't list english as their native language, then keep one of each game

```{r}
nonNativeSpeaker <- rawAggregated %>% 
  filter(nativeEnglish != "yes")

incomplete = rawAggregated %>% 
  group_by(gameid) %>% 
  count(gameid) %>% 
  mutate(numCompleted = n) %>% 
  filter(numCompleted != 24)

missingData = rawAggregated %>%
  filter(is.na(answer))

badGames <- union(
  nonNativeSpeaker$gameid, 
  union(incomplete$gameid, missingData$gameid)
)

d <- rawAggregated %>%
  filter(!(gameid %in% badGames)) %>%
  distinct(domain, goal, question, guess, answer, type, gameid)
  
write_csv(d, "../data/BayesianAnalysisInput.csv")
```

In order to compare different items in a convenient way, we're going to map the questions and answers to the corresponding node positions in the hierarchy. So, in 'branching' trials, for example, 'dalmatian', 'mansion', 'carrot', and 'couch' would all be treated the same.


```{r}
source("./analysisHelpers.R")
d <- mapWordsToNodes(d)
```

We're also going to estimate empirical probabilities for each response, conditioned on the domain, type, and goal of the trial. To get confidence intervals for these estimates, we'll use the bootstrap. Tidy up questioner data...

```{r}
d_q = d %>% 
      mutate(response=ordered(questionNodes, levels=c("Q1","Q2","Q3","Q4"))) %>%
      mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
      group_by(domain, type, goal) %>%
      do(getProbsAndCIs(data = ., QorA = 'q', R = 1000, FALSE)) %>%
      select(goal, type, response, domain, count, lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      # Note that there are no Q3 & Q4 in the equivocal condition
      filter(!(type == "equivocal" & (response == "Q3" | response == "Q4"))) %>%
      mutate(domain = factor(domain),
             type = factor(type),
             goal = ordered(goal, levels=c("G1","G2","G3","G4")))
```

Tidy up answerer data...

```{r}
d_a = d %>% 
      mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
      mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
      group_by(domain, type, utterance) %>%
      do(getProbsAndCIs(data = ., QorA = 'a', R = 1000, FALSE)) %>%
      select(utterance, type, response, domain, count,lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      mutate(domain = factor(domain),
             type = factor(type),
             utterance = ordered(utterance, levels=c("Q1","Q2","Q3","Q4")))
```

# Qualitative Behavioral Results

### Correlations between domains

```{r}
col1 = subset(d_q, domain == "animals")$empProb
col2 = subset(d_q, domain == "places")$empProb
col3 = subset(d_q, domain == "plants")$empProb
col4 = subset(d_q, domain == "artifact")$empProb
corData_q = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('questioner domain correlations:\n')
cor(corData_q)

col1 = subset(d_a, domain == "animals")$empProb
col2 = subset(d_a, domain == "places")$empProb
col3 = subset(d_a, domain == "plants")$empProb
col4 = subset(d_a, domain == "artifact")$empProb
corData_a = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('\nanswerer domain correlations:\n')
cor(corData_a)
```

### Answerer deviation from uniform

for example:

```{r}
# Collapse across domains
overall_distribution = (d_a %>% 
                          group_by(utterance, type, response) %>% 
                          summarize(count = sum(count)))
print(overall_distribution %>% 
        filter(utterance == 'Q4' & type == 'branching') %>%
        mutate(prob = count / sum(count)))
```

statistical test:

```{r}
chisq.test(subset(overall_distribution, 
                  utterance == "Q4"& type == "branching")$count)
```

### Questioner overlapping condition

Make plot

```{r}
gs = c("G1", "G2", "G3", "G4")
qs = c("Q1","Q2","Q3","Q4")
collapsed_q <- d %>% 
    mutate(response = ordered(questionNodes, levels = qs)) %>%
    mutate(goal = ordered(goalNodes, levels = gs)) %>%
    group_by(goal,type) %>%
    filter(type == "overlapping") %>%
    do(getProbsAndCIs(data = ., QorA = 'q', R = 1000, TRUE)) %>%
    mutate(empirical = empProb) %>%
    select(goal, type, response, count, lower_ci, upper_ci, 
           groupSize, empirical)

plottableQ = collapsed_q %>% 
  filter(goal == "G2") %>%
  mutate(response = factor(response, levels = qs, 
                           labels = c('lion?', 'cat?', 'pet?', 'animal?')))

(ggplot(plottableQ, aes(x = response, y = empirical))
 + geom_bar(position = 'dodge', stat= 'identity')
 + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                 position = 'dodge', width =.25)
 + ggtitle("Question asked in overlapping condition when goal is to find 'house cat'")
 + theme_few(12)
 + ylim(0,1)
 + ylab('% participants'))

ggsave("../writing/2016/journal-manuscript/figures/OverlappingModelComparison.pdf", 
       width = 7, height=4)
```

get statistical result

```{r}
cat('Q2:', round(subset(plottableQ, response == 'cat?')$empirical, 2))
cat('\nQ3:', round(subset(plottableQ, response == 'pet?')$empirical, 2))

diffScore <- function(data, indices) {
  d <- data[indices,] %>%
    group_by(response) %>%
    summarize(count = n()) %>%
    ungroup() %>%
    mutate(prob = count / sum(count)) %>%
    select(-count) %>%
    spread(response, prob)
  return(d$Q2 - d$Q3)
}

bootRes = d %>% 
  mutate(response = ordered(questionNodes, levels = c("Q1","Q2","Q3","Q4"))) %>%
  mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
  group_by(goal,type) %>%
  filter(type == "overlapping") %>%
  filter(goal == "G2") %>%
  boot(statistic = diffScore,R=1000) 

estimate <- round(bootRes$t0,2)
lowerDiffScore <- round(boot.ci(bootRes, type = "perc")$percent[4],2)
upperDiffScore <- round(boot.ci(bootRes, type = "perc")$percent[5],2)
cat(paste0(c('\nQ3-Q2 = ', estimate,
             '[', lowerDiffScore, 
             ', ', upperDiffScore, ']')))
```

# Bayesian Data Analysis

## Model Comparison; uniform typicality

```{r}
options( scipen = 0 )
options( digits =1)
computeBayesFactor <- function(name) {
  inputFile <- paste0("../../guessingGame/Bayesian/data/", name, '.csv')
  raw <- read_csv(inputFile, sep = ",", row.names = NULL) 
  # BDA result:
  res <- raw %>% 
    filter(parameter %in% c("modelType", 'expPragFlip')) %>% 
    group_by(value) %>% 
    summarize(prob = sum(MCMCprob)) %>%
    spread(value, prob) 
  print(res)
  return(signif(res$true/res$false, 3))
}
# print(paste0('BF (beta = 0, questioner): ',
#              computeBayesFactor("betaZeroQuestioner_Params")))
# print(paste0('BF (beta = 0, answerer): ',
#              computeBayesFactor("betaZeroAnswerer_Params")))
print(paste0('BF (free beta, questioner): ',
             computeBayesFactor("questionerFixedParams")))
print(paste0('BF (free beta, answerer): ',
      computeBayesFactor("answererFixedParams")))
```