---
title: "Questions and Answers in Dialogue"
output: html_notebook
---

# Imports 

```{r}
library(tidyverse)
library(tidyboot)
library(ggthemes)
library(lme4)
library(lmerTest)

#library(GGally)
# library(coda)
# library(boot)
# library(cowplot)

source("./analysisHelpers.R")

options("scipen"=1) 
```

Experiment data analysis
--------------------------

Start by setting up exclusion criteria for participants who don't speak english or didn't complete the full task.

```{r}
subjInfo = read_csv("../data/compiled-subject_information.csv")

mturk = read_csv("../data/compiled-mturk.csv") %>%
  mutate(gameid = Answer.id) %>%
  select(workerid, gameid)

rawAggregated = read_csv("../data/compiled-trials_clean.csv") %>%
  right_join(mturk, by = 'workerid') %>%
  right_join(subjInfo, by = 'workerid')
```

Filter out participants who didn't complete all 12 trials, had missing data (i.e. didn't answer for some subset of trials), or didn't list english as their native language, then keep one of each game

```{r}
nonNativeSpeaker <- rawAggregated %>% 
  filter(nativeEnglish != "yes")

incomplete = rawAggregated %>% 
  group_by(gameid) %>% 
  count(gameid) %>% 
  mutate(numCompleted = n) %>% 
  filter(numCompleted != 24)

missingData = rawAggregated %>%
  filter(is.na(answer))

badGames <- union(
  nonNativeSpeaker$gameid, 
  union(incomplete$gameid, missingData$gameid)
)

d <- rawAggregated %>%
  filter(!(gameid %in% badGames)) %>%
  distinct(domain, goal, question, guess, answer, type, gameid)
  
write_csv(d, "../data/BayesianAnalysisInput.csv")
```

In order to compare different items in a convenient way, we're going to map the questions and answers to the corresponding node positions in the hierarchy. So, in 'branching' trials, for example, 'dalmatian', 'mansion', 'carrot', and 'couch' would all be treated the same.


```{r}
d <- mapWordsToNodes(d)
```

We're also going to estimate empirical probabilities for each response, conditioned on the domain, type, and goal of the trial. To get confidence intervals for these estimates, we'll use the bootstrap. Tidy up questioner data...

```{r}
d_q = d %>% 
      mutate(response=ordered(questionNodes, levels=c("Q1","Q2","Q3","Q4"))) %>%
      mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
      group_by(domain, type, goal) %>%
      do(getProbsAndCIs(data = ., QorA = 'q', R = 1000, FALSE)) %>%
      select(goal, type, response, domain, count, lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      # Note that there are no Q3 & Q4 in the equivocal condition
      filter(!(type == "equivocal" & (response == "Q3" | response == "Q4"))) %>%
      mutate(domain = factor(domain),
             type = factor(type),
             goal = ordered(goal, levels=c("G1","G2","G3","G4")))
```

Tidy up answerer data...

```{r}
d_a = d %>% 
      mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
      mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
      group_by(domain, type, utterance) %>%
      do(getProbsAndCIs(data = ., QorA = 'a', R = 1000, FALSE)) %>%
      select(utterance, type, response, domain, count,lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      mutate(domain = factor(domain),
             type = factor(type),
             utterance = ordered(utterance, levels=c("Q1","Q2","Q3","Q4")))
```

# Qualitative Behavioral Results

### Correlations between domains

```{r}
col1 = subset(d_q, domain == "animals")$empProb
col2 = subset(d_q, domain == "places")$empProb
col3 = subset(d_q, domain == "plants")$empProb
col4 = subset(d_q, domain == "artifact")$empProb
corData_q = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('questioner domain correlations:\n')
cor(corData_q)

col1 = subset(d_a, domain == "animals")$empProb
col2 = subset(d_a, domain == "places")$empProb
col3 = subset(d_a, domain == "plants")$empProb
col4 = subset(d_a, domain == "artifact")$empProb
corData_a = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('\nanswerer domain correlations:\n')
cor(corData_a)
```

### Answerer deviation from uniform

for example:

```{r}
# Collapse across domains
overall_distribution = d_a %>% 
  group_by(utterance, type, response) %>% 
  summarize(count = sum(count))

overall_distribution %>% 
  filter(utterance == 'Q4' & type == 'branching') %>%
  mutate(prob = count / sum(count))
```

get CIs for plots

```{r}
collapsed_a = d %>% 
      mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
      mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
      group_by(type, utterance) %>%
      do(getProbsAndCIs(data = ., QorA = 'a', R = 1000, TRUE)) %>%
  mutate(source='empirical')
```

get collapsed model predictives for plot

```{r}
A0 = getRawPredictives('answerer_modelComparisonPredictives', chosenModelType = 'A0_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'A0') 
A1 = getRawPredictives('answerer_modelComparisonPredictives', chosenModelType = 'A1_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'A1') 
A2 = getRawPredictives('answerer_modelComparisonPredictives', chosenModelType = 'A2_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'A2')

models = rbind(A0, A1, A2) %>%
  select(parameter, item1, item2, value, prediction, source) %>%
  rename(question = parameter, answer = value, type = item1, domain = item2) %>%
  do(mutate(., answer = vectorizedMapAnswer(type, gsub(".$", "", answer)))) %>%
  do(mutate(., question = vectorizedMapQuestion(type, question))) %>%
  filter(type == 'branching' & question == "Q4") %>%
  select(domain, answer, prediction, source) %>%
  group_by(answer, source) %>%
  summarize(prob = mean(prediction)) %>%
  ungroup() %>%
  mutate(lower_ci = NA, upper_ci = NA) 
```

Plot:

```{r}
cbPalette = c(rgb(.6, .6, .4), rgb(0, .6, .4), rgb(0, .4, .6), rgb(.4, .4, .4))
collapsed_a %>% 
  filter(utterance == "Q4" & type == "branching") %>%
  ungroup() %>%
  select(-type, -count, -utterance, -groupSize) %>%
  rename(prob = empProb, answer = response) %>%
  mutate(source = 'empirical') %>%
  rbind(models) %>%
  mutate(answer = factor(answer, levels = c('A1', 'A2', 'A3', 'A4'), 
                       labels = c('dalmatian', 'poodle', 'cat', 'whale'))) %>%
  ggplot(aes(x = answer, y = prob, fill = source)) +
    geom_bar(stat='identity', position = 'dodge') +
    geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), color = rgb(0.15,0.15,0.15), 
                  position = position_dodge(width = 0.9), width = 0) +
    theme_few(10) +
    scale_fill_manual(values=cbPalette) +
    facet_grid(~ source) +
    ylim(0,1) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ggtitle("answer in branching condition\nwhen asked 'Where is the animal?'")

ggsave("../writing/2016/journal-manuscript/figures/BranchingModelComparison.pdf", 
       width = 4, height=3)
```

statistical test:

```{r}
chisq.test(subset(overall_distribution, 
                  utterance == "Q4"& type == "branching")$count)
```

### Questioner overlapping condition

Make plot

```{r}
gs = c("G1", "G2", "G3", "G4")
qs = c("Q1","Q2","Q3","Q4")
collapsed_q <- d %>% 
  mutate(response = ordered(questionNodes, levels = qs)) %>%
  mutate(goal = ordered(goalNodes, levels = gs)) %>%
  group_by(goal,type) %>%
  filter(type == "overlapping") %>%
  do(getProbsAndCIs(data = ., QorA = 'q', R = 1000, TRUE)) %>%
  mutate(empirical = empProb) %>%
  select(goal, type, response, count, lower_ci, upper_ci, 
         groupSize, empirical) %>%
  mutate(source = 'empirical')
```

```{r}
Q0 = getRawPredictives('questioner_modelComparisonPredictives', chosenModelType = 'Q0_unif') %>%
  filter(alpha == 10 & beta == 0) %>%
  mutate(source = 'Q0') 
Q1 = getRawPredictives('questioner_modelComparisonPredictives', chosenModelType = 'Q1_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'Q1') 
Q2 = getRawPredictives('questioner_modelComparisonPredictives', chosenModelType = 'Q2_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'Q2')

models = rbind(Q0, Q1, Q2) %>%
  select(parameter, item1, item2, value, prediction, source) %>%
  rename(goal = parameter, question = value, type = item1, domain = item2) %>%
  do(mutate(., goal = vectorizedMapGoal(type, goal))) %>%
  do(mutate(., question = vectorizedMapQuestion(type, question))) %>%
  mutate(goal = ordered(goal, levels = gs)) %>%
  filter(type == 'overlapping' & goal == "G2") %>%
  select(domain, question, prediction, source) %>%
  group_by(question, source) %>%
  summarize(prob = mean(prediction)) %>%
  ungroup() %>%
  mutate(lower_ci = NA, upper_ci = NA) 
```

plot 

```{r}
cbPalette = c(rgb(.6, .6, .4), rgb(0, .6, .4), rgb(0, .4, .6), rgb(.4, .4, .4))
plottableQ = collapsed_q %>% 
  filter(goal == "G2") %>%
  ungroup() %>%
  select(-type, -count, -goal, -groupSize) %>%
  rename(prob = empirical, question = response) %>%
  mutate(source = 'empirical') %>%
  rbind(models) %>%
  mutate(question = factor(question, levels = qs, 
                           labels = c('lion?', 'cat?', 'pet?', 'animal?'))) %>%
  mutate(source = ordered(source, levels = c('Q0', 'Q1', 'Q2', 'empirical')))

(ggplot(plottableQ, aes(x = question, y = prob, fill =source))
 + geom_bar(position = 'dodge', stat= 'identity')
 + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                 position =position_dodge(width = 0.9), width =0, color = rgb(.15, .15, .15)) 
 + ggtitle("question in overlapping condition\nwhen goal is to find 'house cat'")
 + theme_few(10)
 + scale_fill_manual(values=cbPalette) 
 + facet_grid(~ source)
 + ylim(0,1)
 + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
 + ylab('% participants'))


ggsave("../writing/2016/journal-manuscript/figures/OverlappingModelComparison.pdf", 
       width = 4, height=3)
```

get statistical result

```{r}
cat('Q2:', round(subset(plottableQ, response == 'cat?')$empirical, 2))
cat('\nQ3:', round(subset(plottableQ, response == 'pet?')$empirical, 2))

diffScore <- function(data, indices) {
  d <- data[indices,] %>%
    group_by(response) %>%
    summarize(count = n()) %>%
    ungroup() %>%
    mutate(prob = count / sum(count)) %>%
    select(-count) %>%
    spread(response, prob)
  return(d$Q2 - d$Q3)
}

bootRes = d %>% 
  mutate(response = ordered(questionNodes, levels = c("Q1","Q2","Q3","Q4"))) %>%
  mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
  group_by(goal,type) %>%
  filter(type == "overlapping") %>%
  filter(goal == "G2") %>%
  boot(statistic = diffScore,R=1000) 

estimate <- round(bootRes$t0,2)
lowerDiffScore <- round(boot.ci(bootRes, type = "perc")$percent[4],2)
upperDiffScore <- round(boot.ci(bootRes, type = "perc")$percent[5],2)
cat(paste0(c('\nQ3-Q2 = ', estimate,
             '[', lowerDiffScore, 
             ', ', upperDiffScore, ']')))
```

# Interactive Experiment

## Model Comparison 

```{r}
modelComparison <- function(name, useTypicality) {
  # beta <- ifelse(useTypicality, NA, 0)
  data <- getRawParams(name)#, chosenBeta = beta)
  View(data)
  return(data %>% 
    group_by(modelType) %>% 
    summarize(prob = reduce(logLikelihood, sumlogprob) - log(length(logLikelihood)))
  )
}
```

Answerers:

```{r}
library(ggforce)
# Marginalize over alpha
comp.ans = modelComparison("answerer_modelComparisonParams")%>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, answerer)', exp(comp.ans$A2_unif - comp.ans$A1_unif))

modelComparison("answerer_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('A0', 'A1', 'A2'))) %>%
  ggplot(aes(x = model, y = prob, alpha=saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = cbPalette) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/answererLogLikelihoods.pdf", 
       width = 2, height=3)
```
zoomed in facet

```{r}
modelComparison("answerer_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('A0', 'A1', 'A2'))) %>%
  filter(model != 'A0') %>%
  ggplot(aes(x = model, y = prob, alpha=saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('') +
    scale_fill_manual(values = tail(cbPalette, 3)) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    coord_cartesian(ylim=c(-900, -500)) +
    theme(legend.position = 'top', 
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg 
ggsave("../writing/2016/journal-manuscript/figures/answererLogLikelihoodsZoomed.pdf", 
       width = 1.5, height=3)
```

```{r}
comp.quest = modelComparison("questioner_modelComparisonParams") %>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, questioner)', exp(comp.quest$Q2_unif - comp.quest$Q1_unif))

modelComparison("questioner_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('Q0', 'Q1', 'Q2'))) %>%
  ggplot(aes(x = model, y = prob, alpha = saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(fill=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = cbPalette) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/questionerLogLikelihoods.pdf", 
       width = 2, height=3)
```

Inset

```{r}
modelComparison("questioner_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  filter(model != "Q0") %>%
  mutate(model = ordered(model, levels = c('Q1', 'Q2'))) %>%
  ggplot(aes(x = model, y = prob, alpha = saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = tail(cbPalette, 3)) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    coord_cartesian(ylim=c(-350, -300)) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/questionerLogLikelihoodsZoomed.pdf", 
       width = 1.5, height=3)
```

## Examine parameter posteriors

Set up helper functions. Note that we only look at the parameter posterior for the model that won our model comparison (otherwise this would be a mixture of the best parameters for each model we considered)

```{r}
examineParams <- function(name, useTypicality, winningModel) {
  beta <- ifelse(useTypicality, NA, 0)

  samples = getRawParams(name, chosenBeta = beta, chosenModelType = winningModel) %>% 
    mutate(MCMCprob = exp(MCMCprob)) %>%
    filter(MCMCprob > 0.001) %>%
    mutate(n = floor(MCMCprob*1000)) %>%
    do(data.frame(.[rep(1:nrow(.), .$n),])) %>%
    select(-t, -n, -MCMCprob) %>%
    gather(parameter, value) %>%
    mutate(value = as.numeric(as.character( value)))

  printTable(samples)
  
  questionParamPosterior <- ggplot(samples, aes(x = value))+
      geom_histogram(aes(y=..density..), 
                   data =subset(samples, parameter == "alpha" ), 
                   binwidth = .25, colour="black", fill="white") +
      geom_histogram(aes(y=..density..), 
                   data=subset(samples, parameter == "beta"), 
                   binwidth = .05, colour="black", fill="white") +
      geom_density(aes(y=..density..),
                   data =subset(samples, parameter == "alpha" ), 
                   adjust = 2, alpha=.2, fill="#FF6666")+
      geom_density(aes(y=..density..),
                   data=subset(samples, parameter == "beta"), 
                   adjust = 5, alpha=.2, fill="#FF6666")+
      facet_wrap(~parameter, scales = 'free') +
      theme_few(10)
  
  print(questionParamPosterior)
  outputName = paste0("../writing/2016/journal-manuscript/figures/",
                     name, ".pdf")
  ggsave(outputName, questionParamPosterior, 
         width = 6, height = 3, bg = "transparent")
}
```

Answerer (no typicality)

```{r}
examineParams('answerer_modelComparisonParams', useTypicality=FALSE, winningModel = 'pragmatic')
```

Questioner (no typicality)

```{r}
examineParams('questioner_modelComparisonParams', useTypicality=TRUE, winningModel = 'pragmatic')
```

## Examine posterior predictives

```{r}
examinePredictives <- function(name, winningModel) {
  inputname <- paste0('../../guessingGame/Bayesian/data/', name, '.csv')
  beta <- NA
  QorA <- toupper(substr(strsplit(name, '_')[[1]][1], 0, 1))
  samples = getRawPredictives(name, chosenBeta = beta, chosenModelType = winningModel) %>% 
    rawPredictivesToSamples()

  predictive = recode(samples, QorA)

  cor_label = round(cor(predictive$MAP, predictive$empProb), 2)
  title = paste0(winningModel, ' ', strsplit(name, '_')[[1]][1], " Posterior Predictive")
  
  predictive.plot = (ggplot(predictive, aes(x = MAP, y = empProb))
    + xlab("")
    + ylim(0,1)
    + ylab("")
    #+ geom_errorbar(aes(ymax = upper_ci, ymin = lower_ci))
    #+ geom_errorbarh(aes(xmax = credHigh, xmin = credLow))
    + geom_point(alpha = .5, size=1.5)#aes(colour = domain, shape = type),  size = 2)
    + geom_abline(intercept = 0, slope = 1, linetype = "dotted")
    + scale_x_continuous(lim = c(0,1), breaks=c(0,.5,1))
#    + ggtitle(title)
    #+ geom_smooth(method = "lm")
    + annotate('text', label = paste0('r =',cor_label), x= 0.8, y = 0.1)
    + coord_fixed()
    + theme_few(10)
    + theme(aspect.ratio = 1) 
    # + theme(rect = element_rect(fill = "transparent"), # bg of the panel
    #         panel.background = element_rect(fill = "transparent",colour = NA),
    #         plot.background = element_rect(fill = "transparent",colour = NA),
    #         panel.grid.major = element_blank(), # get rid of major grid
    #         panel.grid.minor = element_blank(), # get rid of minor grid
    #         legend.background = element_rect(fill = "transparent",colour = NA),
    #         legend.box.background = element_rect(fill = "transparent",colour = NA) # get rid of legend panel bg
  )
  if(winningModel %in% c('Q2_emp', 'Q1_emp')) {
    predictive.plot <- predictive.plot + 
      geom_point(data = subset(predictive, type == 'overlapping'), 
                 aes(x = MAP, y = empProb), color = rgb(0, .5, .8))
  }

  outputfile <- paste0('../writing/2016/journal-manuscript/figures/',
                       name, '_model', winningModel, '.pdf')
  ggsave(outputfile, predictive.plot,
         width = 1.8, height = 1.8, bg = "transparent")
  return(predictive.plot)
}
```

Answerer (no typicality)

```{r}
A1 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A1_unif')
A2 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A2_unif')
#plot_grid(A1, A2, A3, A4, nrow = 2, ncol = 2)
```

Questioner (no typicality)

```{r}
Q1 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q1_unif')
Q2 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q2_unif')
#plot_grid(Q1, Q2, nrow = 1)
```

# Enriching with typicality

```{r}
typPs = read.csv("../data/priorsExperiment-subject_information.csv")

nonNative = typPs %>% 
  filter(!(language %in% c("english", "English")))

confused = typPs %>% 
  filter(asses != "Yes")

badGames = union(nonNative$workerid, confused$workerid)

cat("We removed", length(nonNative$workerid), "ps due to native language")
cat("and", length(setdiff(confused$workerid, nonNative$workerid)), "more due to confusion")

typData = read.csv("../data/priorsExperiment-trials.csv") %>%
  filter(!(workerid %in% badGames)) 

totalCounts = typData %>%
  group_by(domain,type,label) %>%
  summarize(total = n()) 

proportions = typData %>%
  inner_join(totalCounts) %>%
  group_by(domain,type,label,response) %>%
  summarize(prop = n() / mean(total))
```

## Deviations from uniformity

```{r}
chisq.pvals = typData %>% 
  count(domain, type, label, response) %>%
  group_by(domain, type, label) %>%
  filter(length(n) > 1) %>%
  do(data.frame(stat = chisq.test(.$n)$p.value)) %>%
  ungroup() %>%
  select(stat)
length(which(chisq.pvals < 0.05/length(chisq.pvals$stat))) / length(chisq.pvals$stat)
```

### Model comparison

```{r}
# Marginalize over alpha
comp.ans = modelComparison("answerer_modelComparisonParams") %>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, questioner)', exp(comp.ans$A2_emp - comp.ans$A1_emp))

comp.quest = modelComparison("questioner_modelComparisonParams") %>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, questioner)', exp(comp.quest$Q2_emp - comp.quest$Q1_emp))
```

### Typicality test

Savage-Dickey

```{r}
exp(comp.ans$A2_emp - comp.ans$A2_unif)
exp(comp.quest$Q2_emp - comp.quest$Q2_unif)
```

### Examine predictives 

Answerer 

```{r}
A1 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A1_emp')
A2 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A2_emp')
#plot_grid(A1, A2)
```

Questioner

```{r}
Q1 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q1_emp')
Q2 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q2_emp')
#plot_grid(Q1, Q2)
```

# Make Clark simulation figure from model output on forest.db

## Questioner distributions

```{r}
library(jsonlite)
library(dplyr)
library(ggplot2)
library(ggthemes)
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/questionerWithAmExQUD.json') %>% mutate(source = 'AmEx'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/questionerWithBigQUD.json') %>% mutate(source = 'All cards')) %>%
  separate(x, into = c('garbage', 'newX'), sep = 'Do you accept ') %>%
  select(-garbage) %>%
  mutate(y = y + 0.01) %>%
  mutate(x = factor(newX, levels = c("AmericanExpress?", "MasterCard?", "Visa?", "CarteBlanche?", "Diners?", "credit cards?"))) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1.01) +
  xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1, 
        axis.text.y = element_text(size=10),
        axis.text.x = element_text(size=10, angle=90, hjust=1), 
        text = element_text(size=12)) 

ggsave('../writing/2016/journal-manuscript/figures/questionerOutput.pdf', height = 4.51, width = 7.29)
```

```{r}
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/QUDposteriorQ1.json') %>% mutate(source = 'Q1'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/QUDposteriorQ5.json') %>% mutate(source = 'Q5'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/QUDprior.json') %>% mutate(source = 'prior')) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1) +
  xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1,  
        text = element_text(size=10), 
        axis.text.y = element_text(size=10),
        axis.text.x = element_text(size=10)) 

ggsave('../writing/2016/journal-manuscript/figures/goalPosteriors.pdf', height = 4.51, width = 7.29)
```
```{r}
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/answerWithQ1.json') %>% mutate(source = 'Q1'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/answerWithQ5.json') %>% mutate(source = 'Q5')) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1) +
  #xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1,  
        text = element_text(size=12), 
        axis.text.y = element_text(size=12),
        axis.text.x = element_text(size=12)) 
ggsave('../writing/2016/journal-manuscript/figures/answererOutput.pdf', height = 4.51, width = 7.29)
```

# Cards experiment

## Questioner behavior

Sanity check: number complete games

```{r}
read_tsv('../experiments/CardsExperiment1/data/chatMessage/chatMessage.csv') %>% 
  filter(iterationName == 'full_sample') %>% group_by(gameid, trialNum) %>% tally() %>% 
  select(-n) %>% group_by(gameid) %>% tally() %>% filter(n == 6)
```

Pre-processing

```{r}
d.subjInfo <- read_tsv('../experiments/CardsExperiment1/data/exitSurvey/exitSurvey.csv') %>% 
  rename(finalRole = role, understandsInstructions = confused) %>% 
  filter(iterationName == 'full_sample')

d.questioner.raw <- read_tsv('../experiments/CardsExperiment1/data/chatMessage/chatMessage_annotated.csv')  %>% 
  filter(iterationName == 'full_sample') %>%
  group_by(gameid, trialNum) %>% 
  mutate(i = row_number()) %>% 
  ungroup() %>%
  mutate(participantID = paste(gameid, trialNum %% 2, sep = '-'),
         finalRole = ifelse(trialNum %% 2 == 1, 'seeker', 'helper')) %>%
  left_join(d.subjInfo, by = c('gameid', 'finalRole')) %>%
  mutate(participantID = as.numeric(factor(participantID))) %>%
  mutate(trialType = factor(trialType, levels = c('catch', 'baseline', 'overlap'), 
                            labels = c('catch', 'baseline', 'overlap'))) %>%
  separate(targetGoalSet, into = c('target1', 'target2'), by = ',', remove = F) %>%
  separate(distractorGoalSet, into = c('distractor1', 'distractor2'), by = ',', remove = F) %>%
  select(-eventType.x, -eventType.y, -time.y)

incompleteIDs <- unique((d.questioner.raw %>% 
                           group_by(gameid) %>% mutate(trialsComplete = max(trialNum) + 1) %>%
                           filter(trialsComplete != 6))$gameid)
confused_people <- unique((d.questioner.raw %>% 
                             filter(understandsInstructions != 'yes'))$participantID)
nonNative_people <- unique((d.questioner.raw %>% filter(nativeEnglish != 'yes'))$participantID)
instructionViolation_people <- unique((d.questioner.raw %>% 
                                      filter(cardAskedAbout %in% c('BOTH', '?')))$participantID)
catchTrialFail_people <- unique((d.questioner.raw %>% 
                                   filter(trialType == 'catch') %>% 
                                   group_by(participantID) %>%
                                   summarize(firstIncorrect = first(cardAskedAbout) != first(target1),
                                             numExchanges = n(),
                                             cardAskedAbout = first(cardAskedAbout), 
                                             target1 = first(target1),
                                             distractor1 = first(distractor1)) %>%
                                   filter(firstIncorrect))$participantID)

badGames <- c(incompleteIDs)
badParticipants <- c(nonNative_people, confused_people, instructionViolation_people, catchTrialFail_people)

d.questioner <- d.questioner.raw %>%
  filter(!(gameid %in% badGames)) %>%
  filter(!(participantID %in% badParticipants)) %>%
  group_by(participantID, trialNum, trialType) %>%
  summarize(firstAskedAbout = ifelse(first(cardAskedAbout) == first(target1), 'target card 1',
                               ifelse(first(cardAskedAbout == first(target2)), 'target card 2',
                                 ifelse(first(cardAskedAbout) %in% c(first(distractor1), first(distractor2)), 
                                        'distractor', 'other')))) 

```

```{r}
d.questioner %>%
  group_by(trialType) %>%
  mutate(total = n()) %>%
  group_by(trialType, firstAskedAbout) %>%
  summarize(n = n(), p = n / mean(total)) %>%
  filter(trialType != 'catch') %>%
  ggplot(aes(x = trialType, y = p, fill = firstAskedAbout)) +
    geom_bar(stat = 'identity') +
    #geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    theme_few() +
    xlab('trial type') +
    ylab('% questions about target card')
  
ggsave('questionerResults.pdf')
```

NOTE: Should probably do mixed-effects glmer with participant ID random effects 

```{r}
d.questioner %>%
  group_by(trialType) %>%
  mutate(total = n()) %>%
  group_by(trialType, firstAskedAbout) %>%
  summarize(n = n(), p = n / mean(total))
chisq <- chisq.test(matrix(c(28,29,43,16), nrow = 2))
chisq
```

```{r}
d.questioner %>% group_by(participantID, trialNum, trialType) %>% tally() %>% select(-n) %>% group_by(trialType) %>% tally()
```

## Answerer behavior

```{r}
d.answerer.raw <- left_join(read_tsv('../experiments/CardsExperiment1/data/reveal/reveal.csv') %>%
                          group_by(gameid,trialNum) %>% mutate(i = row_number()) %>% 
                          ungroup(),
                        d.questioner.raw %>%  select(gameid, trialNum, trialType, target1, target2, distractor1, distractor2, cardAskedAbout, i, participantID),
            by = c('gameid', 'trialNum', 'trialType', 'i')) %>% 
  filter(iterationName == 'full_sample') %>%
  mutate(finalRole = ifelse(trialNum %% 2 == 1, 'helper', 'seeker')) %>%
  left_join(d.subjInfo, by = c('gameid', 'finalRole')) %>%
  mutate(trialType = factor(trialType, levels = c('catch', 'baseline', 'overlap'), 
                            labels = c('catch', 'baseline', 'overlap'))) %>%
  group_by(participantID, trialNum) %>%
  filter(!(cardAskedAbout %in% c('BOTH', '?'))) %>%
  separate(revealedObjs, into = c('revealed1', 'revealed2')) 

confused_people <- unique((d.answerer.raw %>% 
                             filter(understandsInstructions != 'yes'))$participantID)
nonNative_people <- unique((d.answerer.raw %>% filter(nativeEnglish != 'yes'))$participantID)
catchTrialFail_people <- unique((d.answerer.raw %>% 
                                   filter(trialType == 'catch') %>% 
                                   group_by(participantID, trialNum, trialType) %>%
                                   summarize(firstIncorrect = first(cardAskedAbout) != first(target1),
                                             numExchanges = n(),
                                             numRevealed = first(numRevealed),
                                             revealedIncorrect = first(revealed1) != first(cardAskedAbout),
                                             cardAskedAbout = first(cardAskedAbout), 
                                             target1 = first(target1),
                                             revealed1 = first(revealed1),
                                             distractor1 = first(distractor1)) %>%
                                   filter(firstIncorrect || revealedIncorrect || numRevealed > 1))$participantID)

badParticipants <- c(nonNative_people, confused_people, catchTrialFail_people)

d.answerer <- d.answerer.raw %>%
  filter(!(gameid %in% badGames)) %>%
  filter(!(participantID %in% badParticipants)) %>%
  group_by(participantID, trialNum, trialType) %>%
  mutate(firstAskedAbout = ifelse(first(cardAskedAbout) == first(target1), 'target card 1',
                              ifelse(first(cardAskedAbout == first(target2)), 'target card 2',
                              ifelse(first(cardAskedAbout) %in% c(first(distractor1), first(distractor2)), 
                                      'distractor', 'other')))) 


```

Break out by question being asked... 

```{r}
d.answerer %>%
  filter(trialType != 'catch') %>%
  filter(i == 1) %>%
  rowwise() %>%
  group_by(gameid, trialNum, trialType) %>%
  mutate(target1Revealed = ifelse(firstAskedAbout == 'distractor', 
                                  distractor1 %in% c(revealed1, revealed2),
                                  target1 %in% c(revealed1, revealed2)),
         target2Revealed = ifelse(firstAskedAbout == 'distractor', 
                                  distractor2 %in% c(revealed1, revealed2), 
                                  target2 %in% c(revealed1, revealed2)),
         complete = target1Revealed & target2Revealed,
         literal = cardAskedAbout == revealed1 && numRevealed == 1) %>%
  summarize(answer = ifelse(first(literal), 'literal', 
                            ifelse(!(first(literal)) & first(complete), 'pragmatic', 'other')),
            cardAskedAbout = first(cardAskedAbout), revealed1 = first(revealed1), revealed2 = first(revealed2),
            targetGoalSet = first(targetGoalSet), distractorGoalSet = first(distractorGoalSet),
            firstAskedAbout = first(firstAskedAbout),
            complete = first(complete), literal = first(literal), target1 = first(target1), target2 = first(target2)) %>%
  filter(firstAskedAbout %in% c('target card 1', 'target card 2', 'distractor')) %>%
  group_by(trialType, firstAskedAbout) %>%
  mutate(total = n()) %>%
  group_by(trialType, firstAskedAbout, answer) %>%
  summarize(n = n(), p = n / mean(total)) %>%
  ggplot(aes(x = trialType, y = p, fill = answer)) +
    geom_bar(stat = 'identity') +
  facet_wrap(~ firstAskedAbout) +
    #geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0, position = position_dodge(width = 0.9)) +
    theme_bw() +
    ylim(0,1) +
    xlab('trial type') +
    ylab('% responding with literal answer')
```

## Additional analyses

### number of exchanges taken (combined success of questioner/answerer)

Number of exchanges taken on average to complete the goal

```{r}
d.answerer %>%
  group_by(participantID, trialNum, trialType) %>%
  summarize(correct = n() == 1) %>%
  group_by(trialType) %>%
  tidyboot_mean(correct) %>%
  ggplot(aes(x = trialType, y = empirical_stat)) +
    geom_bar(stat = 'identity') +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    theme_bw() +
    coord_cartesian(ylim = c(0, 1)) +
    #ylim(.9, 2) +
    ylab('% success in single exchange')
```

```{r}
summary(lmer(correct ~ trialType + (1 | participantID), data = d.questioner %>%
  group_by(gameid, trialNum, trialType, participantID) %>%
  summarize(correct = n() == 1) %>% 
    filter(trialType != 'catch')
))
contrasts(combined$trialType)
```

### Learning?

```{r}
d.answerer %>%
  group_by(gameid, trialNum, trialType) %>%
  tally() %>%
  rename(numAttempts = n) %>%
  group_by(trialNum) %>%
  tidyboot_mean(numAttempts) %>%
  ggplot(aes(x = trialNum, y = empirical_stat)) +
    geom_line() +
    geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0) +
    theme_bw() +
    ylab('# attempts')
```

Check whether some answerers just don't realize they can reveal 2 cards?

```{r}
d.answerer %>%
  group_by(participantID, trialNum, trialType) %>%
  filter(trialType != 'catch') %>%
  summarize(revealedOne = 1 %in% numRevealed) %>%
  group_by(participantID) %>%
  mutate(trialNum = ifelse(trialNum == first(trialNum), 'earlier', 'later')) %>%
  ungroup() %>%
  ggplot(aes(x = trialNum, y = 1, fill = revealedOne, group = interaction(trialNum, trialType))) +
    geom_bar(stat = 'identity') +
    theme_bw() +
    facet_wrap(~ participantID) +
    #ylim(.9, 2) +
    ylab('# attempts')
```

Check whether answerers just aren't looking at goal sets?

Filter by order effect of having been questioner already?

```{r}
d.answerer %>%
  group_by(participantID, trialNum, trialType) %>%
  filter(trialType != 'catch') %>%
  summarize(revealedOne = 1 %in% numRevealed) %>%
  group_by(participantID) %>%
  mutate(trialNum = ifelse(trialNum == first(trialNum), 'earlier', 'later')) %>%
  ungroup() %>%
  ggplot(aes(x = trialNum, y = 1, fill = revealedOne, group = interaction(trialNum, trialType))) +
    geom_bar(stat = 'identity') +
    theme_bw() +
    facet_wrap(~ participantID) +
    #ylim(.9, 2) +
    ylab('# attempts')
```