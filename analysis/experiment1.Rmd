---
title: "Questions and Answers in Dialogue"
output: html_notebook
---

# Imports 

```{r}
library(tidyverse)
library(tidyboot)
library(ggthemes)
library(lme4)
library(lmerTest)
library(brms)

#library(GGally)
# library(coda)
# library(boot)
# library(cowplot)

source("./analysisHelpers.R")

options("scipen"=1) 
```

Experiment 1 data analysis
--------------------------

Start by setting up exclusion criteria for participants who don't speak english or didn't complete the full task.

```{r}
subjInfo = read_csv("../data/compiled-subject_information.csv")

mturk = read_csv("../data/compiled-mturk.csv") %>%
  mutate(gameid = Answer.id) %>%
  select(workerid, gameid)

rawAggregated = read_csv("../data/compiled-trials_clean.csv") %>%
  right_join(mturk, by = 'workerid') %>%
  right_join(subjInfo, by = 'workerid')
```

Filter out participants who didn't complete all 12 trials, had missing data (i.e. didn't answer for some subset of trials), or didn't list english as their native language, then keep one of each game

```{r}
nonNativeSpeaker <- rawAggregated %>% 
  filter(nativeEnglish != "yes")

incomplete = rawAggregated %>% 
  group_by(gameid) %>% 
  count(gameid) %>% 
  mutate(numCompleted = n) %>% 
  filter(numCompleted != 24)

missingData = rawAggregated %>%
  filter(is.na(answer))

badGames <- union(
  nonNativeSpeaker$gameid, 
  union(incomplete$gameid, missingData$gameid)
)

d <- rawAggregated %>%
  filter(!(gameid %in% badGames)) %>%
  distinct(domain, goal, question, guess, answer, type, gameid)
  
write_csv(d, "../data/BayesianAnalysisInput.csv")
```

In order to compare different items in a convenient way, we're going to map the questions and answers to the corresponding node positions in the hierarchy. So, in 'branching' trials, for example, 'dalmatian', 'mansion', 'carrot', and 'couch' would all be treated the same.


```{r}
d <- mapWordsToNodes(d)
```

We're also going to estimate empirical probabilities for each response, conditioned on the domain, type, and goal of the trial. To get confidence intervals for these estimates, we'll use the bootstrap. Tidy up questioner data...

```{r}
d_q = d %>% 
      mutate(response=ordered(questionNodes, levels=c("Q1","Q2","Q3","Q4"))) %>%
      mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
      group_by(domain, type, goal) %>%
      do(suppressWarnings(getProbsAndCIs(data = ., QorA = 'q', R = 1000, FALSE))) %>%
      select(goal, type, response, domain, count, lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      # Note that there are no Q3 & Q4 in the equivocal condition
      filter(!(type == "equivocal" & (response == "Q3" | response == "Q4"))) %>%
      mutate(domain = factor(domain),
             type = factor(type),
             goal = ordered(goal, levels=c("G1","G2","G3","G4")))
```

Tidy up answerer data...

```{r}
d_a = d %>% 
      mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
      mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
      group_by(domain, type, utterance) %>%
      do(getProbsAndCIs(data = ., QorA = 'a', R = 1000, FALSE)) %>%
      select(utterance, type, response, domain, count,lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      mutate(domain = factor(domain),
             type = factor(type),
             utterance = ordered(utterance, levels=c("Q1","Q2","Q3","Q4")))
```

# Qualitative Behavioral Results

### Correlations between domains

```{r}
col1 = subset(d_q, domain == "animals")$empProb
col2 = subset(d_q, domain == "places")$empProb
col3 = subset(d_q, domain == "plants")$empProb
col4 = subset(d_q, domain == "artifact")$empProb
corData_q = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('questioner domain correlations:\n')
cor(corData_q)

col1 = subset(d_a, domain == "animals")$empProb
col2 = subset(d_a, domain == "places")$empProb
col3 = subset(d_a, domain == "plants")$empProb
col4 = subset(d_a, domain == "artifact")$empProb
corData_a = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('\nanswerer domain correlations:\n')
cor(corData_a)
```

### Answerer deviation from uniform

statistical results:

```{r}
D.ans <- d %>% 
  filter(type == 'branching') %>% 
  filter(questionNodes == 'Q4') %>% 
  group_by(domain, answerNodes) %>% 
  summarize(counts = n()) %>%
  complete(answerNodes,  fill = list(counts = 0)) %>%
  mutate(answerNodes = factor(answerNodes, levels = c('A4', 'A3', 'A2', 'A1'))) %>%
  mutate(A4diff = ifelse(answerNodes == 'A4', 1, 0))

null.A = glmer(counts ~ 1 + (1 | domain), 
           data=D.ans, family=poisson(),
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
summary(null.A)

full.A = glmer(counts ~ 1 + A4diff + (1 + A4diff | domain), 
           data=D.ans, family=poisson(),
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
summary(full.A)

anova(null.A, full.A)
```

get CIs for plots

```{r}
collapsed_a = d %>% 
      mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
      mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
      group_by(type, utterance) %>%
      do(getProbsAndCIs(data = ., QorA = 'a', R = 1000, TRUE)) %>%
  mutate(source='empirical')
```

get collapsed model predictives for plot

```{r}
A0 = getRawPredictives('answerer_modelComparisonPredictives', chosenModelType = 'A0_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'A0') 
A1 = getRawPredictives('answerer_modelComparisonPredictives', chosenModelType = 'A1_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'A1') 
A2 = getRawPredictives('answerer_modelComparisonPredictives', chosenModelType = 'A2_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'A2')

models = rbind(A0, A1, A2) %>%
  select(parameter, item1, item2, value, prediction, source) %>%
  rename(question = parameter, answer = value, type = item1, domain = item2) %>%
  do(mutate(., answer = vectorizedMapAnswer(type, gsub(".$", "", answer)))) %>%
  do(mutate(., question = vectorizedMapQuestion(type, question))) %>%
  #filter(type == 'branching' & question == "Q4") %>%
  select(domain, answer, type, question, prediction, source) %>%
  group_by(answer, source, type, question) %>%
  summarize(prob = mean(prediction)) %>%
  ungroup() %>%
  mutate(lower_ci = NA, upper_ci = NA) 
```

Plot:

```{r}
cbPalette = c(rgb(.6, .6, .4), rgb(0, .6, .4), rgb(0, .4, .6), rgb(.4, .4, .4))
collapsed_a %>% 
  filter(utterance == "Q4" & type == "branching") %>%
  ungroup() %>%
  select(-type, -count, -utterance, -groupSize) %>%
  rename(prob = empProb, answer = response) %>%
  mutate(source = 'empirical') %>%
  rbind(models) %>%
  mutate(answer = factor(answer, levels = c('A1', 'A2', 'A3', 'A4'), 
                       labels = c('dalmatian', 'poodle', 'cat', 'whale'))) %>%
  ggplot(aes(x = answer, y = prob, fill = source)) +
    geom_bar(stat='identity', position = 'dodge') +
    geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), color = rgb(0.15,0.15,0.15), 
                  position = position_dodge(width = 0.9), width = 0) +
    theme_few(10) +
    scale_fill_manual(values=cbPalette) +
    facet_grid(~ source) +
    ylim(0,1) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ggtitle("answer in branching condition\nwhen asked 'Where is the animal?'")

ggsave("../writing/2016/journal-manuscript/figures/BranchingModelComparison.pdf", 
       width = 4, height=3)
```

### Questioner overlapping condition

get statistical result

```{r}
D.quest <- d %>% 
  filter(type == "overlapping") %>%
  filter(goalNodes == "G2") %>%
  group_by(domain, questionNodes) %>% 
  summarize(counts = n()) %>%
  complete(questionNodes,  fill = list(counts = 0)) %>%
  mutate(Q2Q3_same = ifelse(questionNodes %in% c('Q2', 'Q3'), 1, -1),
         Q2Q3_diff = case_when(questionNodes == 'Q2' ~ 1, 
                               questionNodes == 'Q3' ~ -1, 
                               TRUE ~ 0),
         Q1Q4_diff = case_when(questionNodes == 'Q1' ~ 1, 
                               questionNodes == 'Q4' ~ -1, 
                               TRUE ~ 0))

extra.null.Q = glmer(counts ~ 1 + (1 | domain), 
           data=D.quest, family=poisson,
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
summary(extra.null.Q)

null.Q = glmer(counts ~ 1 + Q2Q3_same + (1 + Q2Q3_same | domain), 
           data=D.quest, family=poisson,
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
summary(null.Q)

full.Q = glmer(counts ~ 1 + Q2Q3_same + Q2Q3_diff + (1 + Q2Q3_same + Q2Q3_diff | domain),
           data=D.quest, family=poisson(), 
           control=glmerControl(optimizer='Nelder_Mead', 
                                optCtrl=list(maxfun=2e5) ))
summary(full.Q)
anova(extra.null.Q, null.Q, full.Q)
```

Make plot

```{r}
gs = c("G1", "G2", "G3", "G4")
qs = c("Q1","Q2","Q3","Q4")
collapsed_q <- d %>% 
  mutate(response = ordered(questionNodes, levels = qs)) %>%
  mutate(goal = ordered(goalNodes, levels = gs)) %>%
  group_by(goal,type) %>%
  filter(type == "overlapping") %>%
  do(getProbsAndCIs(data = ., QorA = 'q', R = 1000, TRUE)) %>%
  mutate(empirical = empProb) %>%
  select(goal, type, response, count, lower_ci, upper_ci, 
         groupSize, empirical) %>%
  mutate(source = 'empirical')

Q0 = getRawPredictives('questioner_modelComparisonPredictives', chosenModelType = 'Q0_unif') %>%
  filter(alpha == 10 & beta == 0) %>%
  mutate(source = 'Q0') 
Q1 = getRawPredictives('questioner_modelComparisonPredictives', chosenModelType = 'Q1_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'Q1') 
Q2 = getRawPredictives('questioner_modelComparisonPredictives', chosenModelType = 'Q2_unif') %>%
  filter(posteriorProb == max(posteriorProb)) %>%
  mutate(source = 'Q2')

models = rbind(Q0, Q1, Q2) %>%
  select(parameter, item1, item2, value, prediction, source) %>%
  rename(goal = parameter, question = value, type = item1, domain = item2) %>%
  do(mutate(., goal = vectorizedMapGoal(type, goal))) %>%
  do(mutate(., question = vectorizedMapQuestion(type, question))) %>%
  mutate(goal = ordered(goal, levels = gs)) %>%
  #filter(type == 'overlapping' & goal == "G2") %>%
  select(domain, question, type, goal, prediction, source) %>%
  group_by(question, source, type, goal) %>%
  summarize(prob = mean(prediction)) %>%
  ungroup() %>%
  mutate(lower_ci = NA, upper_ci = NA) 
```

plot 

```{r}
cbPalette = c(rgb(.6, .6, .4), rgb(0, .6, .4), rgb(0, .4, .6), rgb(.4, .4, .4))
plottableQ = collapsed_q %>% 
  filter(goal == "G2") %>%
  filter(condition == 'overlapping') %>%
  ungroup() %>%
  select(-type, -count, -goal, -groupSize) %>%
  rename(prob = empirical, question = response) %>%
  mutate(source = 'empirical') %>%
  rbind(models) %>%
  mutate(question = factor(question, levels = qs, 
                           labels = c('lion?', 'cat?', 'pet?', 'animal?'))) %>%
  mutate(source = ordered(source, levels = c('Q0', 'Q1', 'Q2', 'empirical')))

(ggplot(plottableQ, aes(x = question, y = prob, fill =source))
 + geom_bar(position = 'dodge', stat= 'identity')
 + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                 position =position_dodge(width = 0.9), width =0, color = rgb(.15, .15, .15)) 
 + ggtitle("question in overlapping condition\nwhen goal is to find 'house cat'")
 + theme_few(10)
 + scale_fill_manual(values=cbPalette) 
 + facet_grid(~ source)
 + ylim(0,1)
 + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
 + ylab('% participants'))


ggsave("../writing/2016/journal-manuscript/figures/OverlappingModelComparison.pdf", 
       width = 4, height=3)
```

# Interactive Experiment

## Model Comparison 

```{r}
modelComparison <- function(name, useTypicality) {
  # beta <- ifelse(useTypicality, NA, 0)
  data <- getRawParams(name)#, chosenBeta = beta)
  return(data %>% 
    group_by(modelType) %>% 
    summarize(prob = reduce(logLikelihood, sumlogprob) - log(length(logLikelihood)))
  )
}
```

Answerers:

```{r}
library(ggforce)
# Marginalize over alpha
comp.ans = modelComparison("answerer_modelComparisonParams")%>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, answerer)', exp(comp.ans$A2_unif - comp.ans$A1_unif))

comp.ans.splitout <- modelComparison("answerer_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('A0', 'A1', 'A2'))) 
ggplot(comp.ans.splitout, aes(x = model, y = prob, alpha=saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = cbPalette) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/answererLogLikelihoods.pdf", 
       width = 2, height=3)
```

Make little latex table

```{r}
comp.ans.splitout %>% spread(saliency, prob)
```
zoomed in facet

```{r}
modelComparison("answerer_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('A0', 'A1', 'A2'))) %>%
  filter(model != 'A0') %>%
  ggplot(aes(x = model, y = prob, alpha=saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('') +
    scale_fill_manual(values = tail(cbPalette, 3)) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    coord_cartesian(ylim=c(-900, -500)) +
    theme(legend.position = 'top', 
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg 
ggsave("../writing/2016/journal-manuscript/figures/answererLogLikelihoodsZoomed.pdf", 
       width = 1.5, height=3)
```

```{r}
comp.quest = modelComparison("questioner_modelComparisonParams") %>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, questioner)', exp(comp.quest$Q2_unif - comp.quest$Q1_unif))

modelComparison("questioner_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('Q0', 'Q1', 'Q2'))) %>%
  ggplot(aes(x = model, y = prob, alpha = saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(fill=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = cbPalette) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/questionerLogLikelihoods.pdf", 
       width = 2, height=3)
```

Inset

```{r}
modelComparison("questioner_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  filter(model != "Q0") %>%
  mutate(model = ordered(model, levels = c('Q1', 'Q2'))) %>%
  ggplot(aes(x = model, y = prob, alpha = saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = tail(cbPalette, 3)) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    coord_cartesian(ylim=c(-350, -300)) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/questionerLogLikelihoodsZoomed.pdf", 
       width = 1.5, height=3)
```

## Examine parameter posteriors

Set up helper functions. Note that we only look at the parameter posterior for the model that won our model comparison (otherwise this would be a mixture of the best parameters for each model we considered)

```{r}
examineParams <- function(name, useTypicality, winningModel) {
  beta <- ifelse(useTypicality, NA, 0)

  samples = getRawParams(name, chosenBeta = beta, chosenModelType = winningModel) %>% 
    mutate(MCMCprob = exp(MCMCprob)) %>%
    filter(MCMCprob > 0.001) %>%
    mutate(n = floor(MCMCprob*1000)) %>%
    do(data.frame(.[rep(1:nrow(.), .$n),])) %>%
    select(-t, -n, -MCMCprob) %>%
    gather(parameter, value) %>%
    mutate(value = as.numeric(as.character( value)))

  printTable(samples)
  
  questionParamPosterior <- ggplot(samples, aes(x = value))+
      geom_histogram(aes(y=..density..), 
                   data =subset(samples, parameter == "alpha" ), 
                   binwidth = .25, colour="black", fill="white") +
      geom_histogram(aes(y=..density..), 
                   data=subset(samples, parameter == "beta"), 
                   binwidth = .05, colour="black", fill="white") +
      geom_density(aes(y=..density..),
                   data =subset(samples, parameter == "alpha" ), 
                   adjust = 2, alpha=.2, fill="#FF6666")+
      geom_density(aes(y=..density..),
                   data=subset(samples, parameter == "beta"), 
                   adjust = 5, alpha=.2, fill="#FF6666")+
      facet_wrap(~parameter, scales = 'free') +
      theme_few(10)
  
  print(questionParamPosterior)
  outputName = paste0("../writing/2016/journal-manuscript/figures/",
                     name, ".pdf")
  ggsave(outputName, questionParamPosterior, 
         width = 6, height = 3, bg = "transparent")
}
```

Answerer (no typicality)

```{r}
examineParams('answerer_modelComparisonParams', useTypicality=FALSE, winningModel = 'pragmatic')
```

Questioner (no typicality)

```{r}
examineParams('questioner_modelComparisonParams', useTypicality=TRUE, winningModel = 'pragmatic')
```

## Examine posterior predictives

```{r}
examinePredictives <- function(name, winningModel) {
  inputname <- paste0('../../guessingGame/Bayesian/data/', name, '.csv')
  beta <- NA
  QorA <- toupper(substr(strsplit(name, '_')[[1]][1], 0, 1))
  samples = getRawPredictives(name, chosenBeta = beta, chosenModelType = winningModel) %>% 
    rawPredictivesToSamples()

  predictive = recode(samples, QorA)

  cor_label = round(cor(predictive$MAP, predictive$empProb), 2)
  title = paste0(winningModel, ' ', strsplit(name, '_')[[1]][1], " Posterior Predictive")
  
  predictive.plot = (ggplot(predictive, aes(x = MAP, y = empProb))
    + xlab("")
    + ylim(0,1)
    + ylab("")
    #+ geom_errorbar(aes(ymax = upper_ci, ymin = lower_ci))
    #+ geom_errorbarh(aes(xmax = credHigh, xmin = credLow))
    + geom_point(alpha = .5, size=1.5)#aes(colour = domain, shape = type),  size = 2)
    + geom_abline(intercept = 0, slope = 1, linetype = "dotted")
    + scale_x_continuous(lim = c(0,1), breaks=c(0,.5,1))
#    + ggtitle(title)
    #+ geom_smooth(method = "lm")
    + annotate('text', label = paste0('r =',cor_label), x= 0.8, y = 0.1)
    + coord_fixed()
    + theme_few(10)
    + theme(aspect.ratio = 1) 
    # + theme(rect = element_rect(fill = "transparent"), # bg of the panel
    #         panel.background = element_rect(fill = "transparent",colour = NA),
    #         plot.background = element_rect(fill = "transparent",colour = NA),
    #         panel.grid.major = element_blank(), # get rid of major grid
    #         panel.grid.minor = element_blank(), # get rid of minor grid
    #         legend.background = element_rect(fill = "transparent",colour = NA),
    #         legend.box.background = element_rect(fill = "transparent",colour = NA) # get rid of legend panel bg
  )
  if(winningModel %in% c('Q2_emp', 'Q1_emp')) {
    predictive.plot <- predictive.plot + 
      geom_point(data = subset(predictive, type == 'overlapping'), 
                 aes(x = MAP, y = empProb), color = rgb(0, .5, .8))
  }

  outputfile <- paste0('../writing/2016/journal-manuscript/figures/',
                       name, '_model', winningModel, '.pdf')
  ggsave(outputfile, predictive.plot,
         width = 1.8, height = 1.8, bg = "transparent")
  return(predictive.plot)
}
```

Answerer (no typicality)

```{r}
A1 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A1_unif')
A2 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A2_unif')
#plot_grid(A1, A2, A3, A4, nrow = 2, ncol = 2)
```

Questioner (no typicality)

```{r}
Q1 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q1_unif')
Q2 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q2_unif')
#plot_grid(Q1, Q2, nrow = 1)
```

# Enriching with typicality

```{r}
typPs = read.csv("../data/priorsExperiment-subject_information.csv")

nonNative = typPs %>% 
  filter(!(language %in% c("english", "English")))

confused = typPs %>% 
  filter(asses != "Yes")

badGames = union(nonNative$workerid, confused$workerid)

cat("We removed", length(nonNative$workerid), "ps due to native language")
cat("and", length(setdiff(confused$workerid, nonNative$workerid)), "more due to confusion")

typData = read.csv("../data/priorsExperiment-trials.csv") %>%
  filter(!(workerid %in% badGames)) 

totalCounts = typData %>%
  group_by(domain,type,label) %>%
  summarize(total = n()) 

proportions = typData %>%
  inner_join(totalCounts) %>%
  group_by(domain,type,label,response) %>%
  summarize(prop = n() / mean(total))
```

## Deviations from uniformity

```{r}
chisq.pvals = typData %>% 
  count(domain, type, label, response) %>%
  group_by(domain, type, label) %>%
  filter(length(n) > 1) %>%
  do(data.frame(stat = chisq.test(.$n)$p.value)) %>%
  ungroup() %>%
  select(stat)
length(which(chisq.pvals < 0.05/length(chisq.pvals$stat))) / length(chisq.pvals$stat)
```

### Model comparison

```{r}
# Marginalize over alpha
comp.ans = modelComparison("answerer_modelComparisonParams") %>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, questioner)', exp(comp.ans$A2_emp - comp.ans$A1_emp))

comp.quest = modelComparison("questioner_modelComparisonParams") %>% 
  spread(modelType, prob) 
cat('\nBF (beta=0, questioner)', exp(comp.quest$Q2_emp - comp.quest$Q1_emp))
```

### Typicality test

Savage-Dickey

```{r}
exp(comp.ans$A2_emp - comp.ans$A2_unif)
exp(comp.quest$Q2_emp - comp.quest$Q2_unif)
```

### Examine predictives 

Answerer 

```{r}
A1 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A1_emp')
A2 = examinePredictives('answerer_modelComparisonPredictives', winningModel = 'A2_emp')
#plot_grid(A1, A2)
```

Questioner

```{r}
Q1 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q1_emp')
Q2 = examinePredictives('questioner_modelComparisonPredictives', winningModel = 'Q2_emp')
#plot_grid(Q1, Q2)
```

# Make Clark simulation figure from model output on forest.db

## Questioner distributions

```{r}
library(jsonlite)
library(dplyr)
library(ggplot2)
library(ggthemes)
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/questionerWithAmExQUD.json') %>% mutate(source = 'AmEx'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/questionerWithBigQUD.json') %>% mutate(source = 'All cards')) %>%
  separate(x, into = c('garbage', 'newX'), sep = 'Do you accept ') %>%
  select(-garbage) %>%
  mutate(y = y + 0.01) %>%
  mutate(x = factor(newX, levels = c("AmericanExpress?", "MasterCard?", "Visa?", "CarteBlanche?", "Diners?", "credit cards?"))) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1.01) +
  xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1, 
        axis.text.y = element_text(size=10),
        axis.text.x = element_text(size=10, angle=90, hjust=1), 
        text = element_text(size=12)) 

ggsave('../writing/2016/journal-manuscript/figures/questionerOutput.pdf', height = 4.51, width = 7.29)
```

```{r}
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/QUDposteriorQ1.json') %>% mutate(source = 'Q1'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/QUDposteriorQ5.json') %>% mutate(source = 'Q5'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/QUDprior.json') %>% mutate(source = 'prior')) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1) +
  xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1,  
        text = element_text(size=10), 
        axis.text.y = element_text(size=10),
        axis.text.x = element_text(size=10)) 

ggsave('../writing/2016/journal-manuscript/figures/goalPosteriors.pdf', height = 4.51, width = 7.29)
```
```{r}
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/answerWithQ1.json') %>% mutate(source = 'Q1'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/answerWithQ5.json') %>% mutate(source = 'Q5')) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1) +
  #xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1,  
        text = element_text(size=12), 
        axis.text.y = element_text(size=12),
        axis.text.x = element_text(size=12)) 
ggsave('../writing/2016/journal-manuscript/figures/answererOutput.pdf', height = 4.51, width = 7.29)
```

