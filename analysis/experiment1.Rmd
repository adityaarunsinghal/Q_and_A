---
title: "Questions and Answers in Dialogue"
output: html_notebook
---

# Imports 

```{r}
library(tidyverse)
library(tidyboot)
library(ggthemes)
library(lme4)
library(lmerTest)
library(brms)
library(coda)
source("./analysisHelpers.R")

options("scipen"=1) 
```

Experiment 1 data analysis
--------------------------

Start by setting up exclusion criteria for participants who don't speak english or didn't complete the full task.

```{r warning=FALSE, results=FALSE}
subjInfo = read_csv("../data/compiled-subject_information.csv")

mturk = read_csv("../data/compiled-mturk.csv") %>%
  mutate(gameid = Answer.id) %>%
  select(workerid, gameid)

rawAggregated = read_csv("../data/compiled-trials_clean.csv") %>%
  right_join(mturk, by = 'workerid') %>%
  right_join(subjInfo, by = 'workerid')
```

Filter out participants who didn't complete all 12 trials, had missing data (i.e. didn't answer for some subset of trials), or didn't list english as their native language, then keep one of each game

```{r}
nonNativeSpeaker <- rawAggregated %>% 
  filter(nativeEnglish != "yes")

incomplete = rawAggregated %>% 
  group_by(gameid) %>% 
  count(gameid) %>% 
  mutate(numCompleted = n) %>% 
  filter(numCompleted != 24)

missingData = rawAggregated %>%
  filter(is.na(answer))

badGames <- union(
  nonNativeSpeaker$gameid, 
  union(incomplete$gameid, missingData$gameid)
)

d <- rawAggregated %>%
  filter(!(gameid %in% badGames)) %>%
  distinct(domain, goal, question, guess, answer, type, gameid)
  
write_csv(d, "../data/BayesianAnalysisInput.csv")
```

In order to compare different items in a convenient way, we're going to map the questions and answers to the corresponding node positions in the hierarchy. So, in 'branching' trials, for example, 'dalmatian', 'mansion', 'carrot', and 'couch' would all be treated the same.


```{r}
d <- mapWordsToNodes(d)
```

We're also going to estimate empirical probabilities for each response, conditioned on the domain, type, and goal of the trial. To get confidence intervals for these estimates, we'll use the bootstrap. Tidy up questioner data...

```{r}
d_q = d %>% 
      mutate(response=ordered(questionNodes, levels=c("Q1","Q2","Q3","Q4"))) %>%
      mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
      group_by(domain, type, goal) %>%
      do(suppressWarnings(getProbsAndCIs(data = ., QorA = 'q', R = 1000, FALSE))) %>%
      select(goal, type, response, domain, count, lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      # Note that there are no Q3 & Q4 in the equivocal condition
      filter(!(type == "equivocal" & (response == "Q3" | response == "Q4"))) %>%
      mutate(domain = factor(domain),
             type = factor(type),
             goal = ordered(goal, levels=c("G1","G2","G3","G4")))
```

Tidy up answerer data...

```{r}
d_a = d %>% 
      mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
      mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
      group_by(domain, type, utterance) %>%
      do(getProbsAndCIs(data = ., QorA = 'a', R = 1000, FALSE)) %>%
      select(utterance, type, response, domain, count,lower_ci, upper_ci,
             groupSize, empProb) %>%
      ungroup() %>%
      mutate(domain = factor(domain),
             type = factor(type),
             utterance = ordered(utterance, levels=c("Q1","Q2","Q3","Q4")))
```

# Qualitative Behavioral Results

### Correlations between domains

```{r}
col1 = subset(d_q, domain == "animals")$empProb
col2 = subset(d_q, domain == "places")$empProb
col3 = subset(d_q, domain == "plants")$empProb
col4 = subset(d_q, domain == "artifact")$empProb
corData_q = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('questioner domain correlations:\n')
cor(corData_q)

col1 = subset(d_a, domain == "animals")$empProb
col2 = subset(d_a, domain == "places")$empProb
col3 = subset(d_a, domain == "plants")$empProb
col4 = subset(d_a, domain == "artifact")$empProb
corData_a = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cat('\nanswerer domain correlations:\n')
cor(corData_a)
```

### Answerer nested condition

statistical results:

```{r}
D.ans <- d %>% 
  filter(type == 'branching') %>% 
  filter(questionNodes == 'Q4') %>% 
  group_by(domain, answerNodes) %>% 
  summarize(counts = n()) %>%
  complete(answerNodes,  fill = list(counts = 0)) %>%
  mutate(answerNodes = factor(answerNodes, levels = c('A4', 'A3', 'A2', 'A1'))) %>%
  mutate(A4diff = ifelse(answerNodes == 'A4', 1, 0))

null.A = glmer(counts ~ 1 + (1 | domain), 
           data=D.ans, family=poisson(),
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
#summary(null.A)

full.A = glmer(counts ~ 1 + A4diff + (1 + A4diff | domain), 
           data=D.ans, family=poisson(),
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
#summary(full.A)

anova(null.A, full.A)
```

### Questioner overlapping condition

get statistical result

```{r}
D.quest <- d %>% 
  filter(type == "overlapping") %>%
  filter(goalNodes == "G2") %>%
  group_by(domain, questionNodes) %>% 
  summarize(counts = n()) %>%
  complete(questionNodes,  fill = list(counts = 0)) %>%
  mutate(Q2Q3_same = ifelse(questionNodes %in% c('Q2', 'Q3'), 1, -1),
         Q2Q3_diff = case_when(questionNodes == 'Q2' ~ 1, 
                               questionNodes == 'Q3' ~ -1, 
                               TRUE ~ 0),
         Q1Q4_diff = case_when(questionNodes == 'Q1' ~ 1, 
                               questionNodes == 'Q4' ~ -1, 
                               TRUE ~ 0))

extra.null.Q = glmer(counts ~ 1 + (1 | domain), 
           data=D.quest, family=poisson,
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
#summary(extra.null.Q)

null.Q = glmer(counts ~ 1 + Q2Q3_same + (1 + Q2Q3_same | domain), 
           data=D.quest, family=poisson,
            control=glmerControl(optimizer='Nelder_Mead', 
                      optCtrl=list(maxfun=2e5) ))
#summary(null.Q)

full.Q = glmer(counts ~ 1 + Q2Q3_same + Q2Q3_diff + (1 + Q2Q3_same + Q2Q3_diff | domain),
           data=D.quest, family=poisson(), 
           control=glmerControl(optimizer='Nelder_Mead', 
                                optCtrl=list(maxfun=2e5) ))
#summary(full.Q)
anova(extra.null.Q, null.Q, full.Q)
```

# Quantitative results

## Model Comparison 

Answerers:

```{r}
comp.ans = read_csv("../modeling/experiment1/bdaOutput/AISoutput_answerer.txt") %>% 
  group_by(model) %>% 
  summarize(likelihood = mean(likelihood)) %>%
  spread(model, likelihood) 
cat('\nBF (answerer)', exp(comp.ans$prag_emp - comp.ans$lit_emp))
cat('\nBF (beta=0, answerer)', exp(comp.ans$prag_emp - comp.ans$prag_unif))
```

```{r}
comp.quest = read_csv("../modeling/experiment1/bdaOutput/AISoutput_questioner.txt") %>% 
  group_by(model) %>% 
  summarize(likelihood = mean(likelihood)) %>%
  spread(model, likelihood) 
cat('\nBF (beta=0, questioner)', exp(comp.quest$prag_emp - comp.quest$lit_emp))
cat('\nBF (beta=0, questioner)', exp(comp.quest$prag_emp - comp.quest$prag_unif))
```

## Examine parameter posteriors

Set up helper functions. Note that we only look at the parameter posterior for the model that won our model comparison (otherwise this would be a mixture of the best parameters for each model we considered)

```{r}
examineParams <- function(params) {
  
  samples = params %>% 
    mutate(MCMCprob = exp(posteriorProb)) %>%
    filter(MCMCprob >= 0.001) %>%
    mutate(n = floor(MCMCprob*500)) %>%
    do(data.frame(.[rep(1:nrow(.), .$n),])) %>%
    select(-n, -MCMCprob, -posteriorProb, -modelType, -logLikelihood) %>%
    gather(parameter, value, alpha_A, alpha_Q, w)

  printTable(samples)
  
  paramPosterior <- ggplot(samples, aes(x = log(value)))+
      geom_histogram(aes(y=..density..), 
                   data =subset(samples, parameter == "alpha_A" ), 
                   binwidth = .1, colour="black", fill="white") +
      geom_histogram(aes(y=..density..), 
                   data=subset(samples, parameter == "alpha_Q"), 
                   binwidth = .25, colour="black", fill="white") +
      geom_histogram(aes(y=..density..), 
                   data =subset(samples, parameter == "w" ), 
                   binwidth = .05, colour="black", fill="white") +
      geom_density(aes(y=..density..),
                   data =subset(samples, parameter == "alpha_A" ), 
                   adjust = 2, alpha=.2, fill="#FF6666")+
      geom_density(aes(y=..density..),
                   data=subset(samples, parameter == "alpha_Q"), 
                   adjust = 3, alpha=.2, fill="#FF6666")+
      geom_density(aes(y=..density..),
                   data=subset(samples, parameter == "w"), 
                   adjust = 1, alpha=.2, fill="#FF6666")+
      facet_grid(parameter ~ source, scales = 'free') +
      theme_few(10)
  
  print(paramPosterior)
  outputName = paste0("../writing/2019/journal-revision/figures/Exp1/best_answerer_params.pdf")
  ggsave(outputName, paramPosterior, width = 6, height = 3, bg = "transparent")
}
```

Answerer params

```{r}
Aparams <- bind_rows(
  read_csv('../modeling/experiment1/bdaOutput/answerer_lit_empParams.csv') %>% mutate(source = 'A1_emp'),
  read_csv('../modeling/experiment1/bdaOutput/answerer_prag_empParams.csv') %>% mutate(source = 'A2_emp'),
  read_csv('../modeling/experiment1/bdaOutput/answerer_lit_unifParams.csv') %>% mutate(source = 'A1_unif'),
  read_csv('../modeling/experiment1/bdaOutput/answerer_prag_unifParams.csv') %>% mutate(source = 'A2_unif')
) 
examineParams(Aparams)
```

Questioner (no typicality)

```{r}
Qparams <- bind_rows(
  read_csv('../modeling/experiment1/bdaOutput/questioner_lit_empParams.csv') %>% mutate(source = 'Q1_emp'),
  read_csv('../modeling/experiment1/bdaOutput/questioner_prag_empParams.csv') %>% mutate(source = 'Q2_emp'),
  read_csv('../modeling/experiment1/bdaOutput/questioner_lit_unifParams.csv') %>% mutate(source = 'Q1_unif'),
  read_csv('../modeling/experiment1/bdaOutput/questioner_prag_unifParams.csv') %>% mutate(source = 'Q2_unif')
)

examineParams(Qparams)
```

## Examine predictives

```{r}
examinePredictives <- function(filename, predictive) {
  predictive.plot = (ggplot(predictive, aes(x = modelProb, y = empProb)) +
   geom_point(alpha = .5, size=1.5) + 
   geom_abline(intercept = 0, slope = 1, linetype = "dotted") +
   scale_x_continuous(lim = c(0,1), breaks=c(0,.5,1)) + 
   geom_text(aes(label = corr_label), x= 0.8, y = 0.1) + 
   coord_fixed() + 
   xlab("") +
   ylim(0,1) +
   ylab("") +
   theme_few(10) + 
   facet_grid( ~ source) +
   theme(aspect.ratio = 1))

  outputfile <- paste0('../writing/2019/journal-revision/figures/Exp1/', filename,'.pdf')
  ggsave(outputfile, predictive.plot,
         width = 7.2, height = 1.8, bg = "transparent")
  return(predictive.plot)
}
```

Answerer (at domain-type-question granularity)

```{r}
Apredictives = bind_rows(
  read_csv('../modeling/experiment1/bdaOutput/answerer_lit_empPredictives.csv') %>% mutate(source = 'A1_emp'),
  read_csv('../modeling/experiment1/bdaOutput/answerer_prag_empPredictives.csv') %>% mutate(source = 'A2_emp'),
  read_csv('../modeling/experiment1/bdaOutput/answerer_lit_unifPredictives.csv') %>% mutate(source = 'A1_unif'),
  read_csv('../modeling/experiment1/bdaOutput/answerer_prag_unifPredictives.csv') %>% mutate(source = 'A2_unif')
) %>%
  left_join(Aparams) %>%
  group_by(source) %>%
  filter(logLikelihood == max(logLikelihood)) %>%
  select(stim, item1, item2, value, prediction, source) %>%
  rename(utterance = stim, response = value, type = item1, domain = item2) %>%
  do(mutate(., response = vectorizedMapAnswer(type, response))) %>%
  do(mutate(., utterance = vectorizedMapQuestion(type, utterance))) %>%
  select(domain, response, type, utterance, prediction, source) %>%
  group_by(source, domain, response, type, utterance) %>%
  summarize(modelProb = mean(prediction)) %>%
  ungroup() %>%
  mutate(lower_ci = NA, upper_ci = NA, source = factor(source, levels = c('A1_unif', 'A2_unif', 'A1_emp', 'A2_emp'))) %>%
  left_join(d_a, by = c('utterance', 'type', 'response', 'domain')) %>%
  group_by(source) %>% 
  mutate(corr_label = paste0('r = ', round(cor(modelProb, empProb), 2)))

examinePredictives('answerer_predictives', Apredictives)
```

Questioner (no typicality)

```{r}
Qpredictives = bind_rows(
  read_csv('../modeling/experiment1/bdaOutput/questioner_lit_empPredictives.csv') %>% mutate(source = 'Q1_emp'),
  read_csv('../modeling/experiment1/bdaOutput/questioner_prag_empPredictives.csv') %>% mutate(source = 'Q2_emp'),
  read_csv('../modeling/experiment1/bdaOutput/questioner_lit_unifPredictives.csv') %>% mutate(source = 'Q1_unif'),
  read_csv('../modeling/experiment1/bdaOutput/questioner_prag_unifPredictives.csv') %>% mutate(source = 'Q2_unif')
) %>%
  left_join(Qparams) %>%
  group_by(source) %>%
  filter(logLikelihood == max(logLikelihood)) %>%
  select(stim, item1, item2, value, prediction, modelType) %>%
  rename(goal = stim, response = value, type = item1, domain = item2) %>%
  do(mutate(., goal = vectorizedMapGoal(type, goal))) %>%
  do(mutate(., response = vectorizedMapQuestion(type, response))) %>%
  select(domain, response, type, goal, prediction, modelType) %>%
  group_by(source, domain, response, type, goal) %>%
  summarize(modelProb = mean(prediction)) %>%
  ungroup() %>%
  mutate(lower_ci = NA, upper_ci = NA, source = factor(source, levels = c('Q1_unif', 'Q2_unif', 'Q1_emp', 'Q2_emp'))) %>%
  left_join(d_q, by = c('goal', 'type', 'response', 'domain')) %>%
  group_by(source) %>% 
  mutate(corr_label = paste0('r = ', round(cor(modelProb, empProb), 2)))

examinePredictives('questioner_predictives', Qpredictives)
```

## examine predictions collapsed across domains for qualitative pattern plots

```{r}
collapsed_a = d %>% 
    filter(type == 'branching') %>%
    mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
    mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
    group_by(type, utterance) %>%
    mutate(total = n()) %>%
    group_by(type, utterance, response) %>%
    summarize(count = n(), prob = count/mean(total)) %>%
    complete(utterance, response, fill = list(count = 0, prob = 0)) %>%
    distinct() %>%
    mutate(source='empirical')

bind_rows(
  read_csv("../modeling/experiment1/bdaOutput/answerer_prag_unifPredictives.csv") %>% mutate(source='A2_unif'),
  read_csv("../modeling/experiment1/bdaOutput/answerer_lit_unifPredictives.csv") %>% mutate(source='A1_unif')
) %>%
  left_join(Aparams) %>%
  group_by(source) %>%
  filter(logLikelihood == max(logLikelihood)) %>%
  select(stim, item1, item2, value, prediction, source) %>%
  rename(utterance = stim, response = value, type = item1, domain = item2) %>%
  filter(type == 'branching') %>%
  do(mutate(., response = vectorizedMapAnswer(type, response))) %>%
  do(mutate(., utterance = vectorizedMapQuestion(type, utterance))) %>%
  select(response, type, utterance, prediction, source) %>%
  group_by(response, source, type, utterance) %>%
  summarize(prob = mean(prediction)) %>%
  ungroup() %>%
  bind_rows(collapsed_a %>% select(-count)) %>%
  spread(source, prob) %>%
  left_join(collapsed_a) %>%
  arrange(utterance, response)
```

```{r}
collapsed_q = d %>% 
    filter(type == 'overlapping') %>%
    mutate(response = ordered(questionNodes, levels = c("Q1","Q2","Q3","Q4"))) %>%
    mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
    group_by(type, goal) %>%
    mutate(total = n()) %>%
    group_by(type, goal, response) %>%
    summarize(count = n(), prob = count/mean(total)) %>%
    complete(goal, response, fill = list(count = 0, prob = 0)) %>%
    distinct() %>%
    mutate(source='empirical')

bind_rows(
  read_csv("../modeling/experiment1/bdaOutput/questioner_prag_unifPredictives.csv") %>% mutate(source='Q2_unif'),
  read_csv("../modeling/experiment1/bdaOutput/questioner_lit_unifPredictives.csv") %>% mutate(source='Q1_unif')
) %>%
  left_join(Qparams) %>%
  group_by(source) %>%
  filter(logLikelihood == max(logLikelihood)) %>%
  select(stim, item1, item2, value, prediction, source) %>%
  rename(goal = stim, response = value, type = item1, domain = item2) %>%
  filter(type=='overlapping') %>%
  do(mutate(., goal = vectorizedMapGoal(type, goal))) %>%
  do(mutate(., response = vectorizedMapQuestion(type, response))) %>%
  select(response, type, goal, prediction, source) %>%
  group_by(source, response, type, goal) %>%
  summarize(prob = mean(prediction)) %>%
  ungroup() %>%
  bind_rows(collapsed_q %>% select(-count)) %>%
  spread(source, prob) %>%
  left_join(collapsed_q) %>%
  select(-prob) %>%
  arrange(goal, response)

```

# Enriching with typicality

```{r}
typPs = read.csv("../data/priorsExperiment-subject_information.csv")

nonNative = typPs %>% 
  filter(!(language %in% c("english", "English")))

confused = typPs %>% 
  filter(asses != "Yes")

badGames = union(nonNative$workerid, confused$workerid)

cat("We removed", length(nonNative$workerid), "ps due to native language")
cat("and", length(setdiff(confused$workerid, nonNative$workerid)), "more due to confusion")

typData = read.csv("../data/priorsExperiment-trials.csv") %>%
  filter(!(workerid %in% badGames)) 

totalCounts = typData %>%
  group_by(domain,type,label) %>%
  summarize(total = n()) 

proportions = typData %>%
  inner_join(totalCounts) %>%
  group_by(domain,type,label,response) %>%
  summarize(prop = n() / mean(total))
```

## Deviations from uniformity

```{r}
chisq.pvals = typData %>% 
  count(domain, type, label, response) %>%
  group_by(domain, type, label) %>%
  filter(length(n) > 1) %>%
  do(data.frame(stat = chisq.test(.$n)$p.value)) %>%
  ungroup() %>%
  select(stat)
length(which(chisq.pvals < 0.05/length(chisq.pvals$stat))) / length(chisq.pvals$stat)
```

# Make Clark simulation figure from model output on forest.db

## Questioner distributions

```{r}
library(jsonlite)
library(tidyverse)
library(ggthemes)
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/questionerWithAmExQUD.json') %>% mutate(source = 'AmEx'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/questionerWithBigQUD.json') %>% mutate(source = 'All cards')) %>%
  separate(x, into = c('garbage', 'newX'), sep = 'Do you accept ') %>%
  select(-garbage) %>%
  mutate(y = y + 0.01) %>%
  mutate(x = factor(newX, levels = c("AmericanExpress?", "MasterCard?", "Visa?", "CarteBlanche?", "Diners?", "credit cards?"))) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1.01) +
  xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1, 
        axis.text.y = element_text(size=10),
        axis.text.x = element_text(size=10, angle=90, hjust=1), 
        text = element_text(size=12)) 

ggsave('../writing/2016/journal-manuscript/figures/questionerOutput.pdf', height = 4.51, width = 7.29)
```

```{r}
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/QUDposteriorQ1.json') %>% mutate(source = 'Q1'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/QUDposteriorQ5.json') %>% mutate(source = 'Q5'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/QUDprior.json') %>% mutate(source = 'prior')) %>%
ggplot(aes(x = x, y = y)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,1) +
  xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1,  
        text = element_text(size=10), 
        axis.text.y = element_text(size=10),
        axis.text.x = element_text(size=10)) 

ggsave('../writing/2019/journal-revision/figures/simulations/clarkExampleFig/goalPosteriors.pdf', height = 4.51, width = 7.29)
```

```{r}
rbind(fromJSON(txt = '../modeling/simulations/outputFromForest/answerWithQ1.json') %>% mutate(source = 'Q1'),
      fromJSON(txt = '../modeling/simulations/outputFromForest/answerWithQ5.json') %>% mutate(source = 'Q5')) %>%
  filter(x == 'exhuastive') %>%
ggplot(aes(x = source, y = y)) +
  geom_bar(stat = 'identity') +
  #facet_wrap(~ source, nrow = 3, ncol = 1) +
  theme_few()+
  ylim(0,.5) +
      #xlab('number of cards') +
  ylab('probability') + 
  theme(aspect.ratio = 1,  
        text = element_text(size=12), 
        axis.text.y = element_text(size=12),
        axis.text.x = element_text(size=12)) 
ggsave('../writing/2019/journal-revision/figures/simulations/clarkExampleFig/answererOutput.pdf', height = 4.51, width = 7.29)
```

# Visualize behavior in qualitative conditions (not in paper)

Plot:

```{r}
cbPalette = c(rgb(.6, .6, .4), rgb(0, .6, .4), rgb(0, .4, .6), rgb(.4, .4, .4))
collapsed_a %>% 
  #filter(utterance == "Q4" & type == "branching") %>%
  ungroup() %>%
  select(-type, -count, -utterance, -groupSize) %>%
  rename(prob = empProb, answer = response) %>%
  mutate(source = 'empirical') %>%
  rbind(models) %>%
  mutate(answer = factor(answer, levels = c('A1', 'A2', 'A3', 'A4'), 
                       labels = c('dalmatian', 'poodle', 'cat', 'whale'))) %>%
  ggplot(aes(x = answer, y = prob, fill = source)) +
    geom_bar(stat='identity', position = 'dodge') +
    geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), color = rgb(0.15,0.15,0.15), 
                  position = position_dodge(width = 0.9), width = 0) +
    theme_few(10) +
    scale_fill_manual(values=cbPalette) +
    facet_grid(~ source) +
    ylim(0,1) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ggtitle("answer in branching condition\nwhen asked 'Where is the animal?'")

ggsave("../writing/2016/journal-manuscript/figures/BranchingModelComparison.pdf", 
       width = 4, height=3)
```


```{r}
cbPalette = c(rgb(.6, .6, .4), rgb(0, .6, .4), rgb(0, .4, .6), rgb(.4, .4, .4))
plottableQ = collapsed_q %>% 
  filter(goal == "G2") %>%
  filter(condition == 'overlapping') %>%
  ungroup() %>%
  select(-type, -count, -goal, -groupSize) %>%
  rename(prob = empirical, question = response) %>%
  mutate(source = 'empirical') %>%
  rbind(models) %>%
  mutate(question = factor(question, levels = qs, 
                           labels = c('lion?', 'cat?', 'pet?', 'animal?'))) %>%
  mutate(source = ordered(source, levels = c('Q0', 'Q1', 'Q2', 'empirical')))

(ggplot(plottableQ, aes(x = question, y = prob, fill =source))
 + geom_bar(position = 'dodge', stat= 'identity')
 + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                 position =position_dodge(width = 0.9), width =0, color = rgb(.15, .15, .15)) 
 + ggtitle("question in overlapping condition\nwhen goal is to find 'house cat'")
 + theme_few(10)
 + scale_fill_manual(values=cbPalette) 
 + facet_grid(~ source)
 + ylim(0,1)
 + theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
 + ylab('% participants'))


ggsave("../writing/2016/journal-manuscript/figures/OverlappingModelComparison.pdf", 
       width = 4, height=3)
```


# Visualize likelihoods (not in paper)

```{r}
comp.ans.splitout <- modelComparison("answerer_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('A0', 'A1', 'A2'))) 
ggplot(comp.ans.splitout, aes(x = model, y = prob, alpha=saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = cbPalette) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg
ggsave("../writing/2016/journal-manuscript/figures/answererLogLikelihoods.pdf", 
       width = 2, height=3)
```

zoomed in facet

```{r}
modelComparison("answerer_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('A0', 'A1', 'A2'))) %>%
  filter(model != 'A0') %>%
  ggplot(aes(x = model, y = prob, alpha=saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('') +
    scale_fill_manual(values = tail(cbPalette, 3)) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    coord_cartesian(ylim=c(-900, -500)) +
    theme(legend.position = 'top', 
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg 
ggsave("../writing/2016/journal-manuscript/figures/answererLogLikelihoodsZoomed.pdf", 
       width = 1.5, height=3)
```

## Same with questions...

```{r}
modelComparison("questioner_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  mutate(model = ordered(model, levels = c('Q0', 'Q1', 'Q2'))) %>%
  ggplot(aes(x = model, y = prob, alpha = saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(fill=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = cbPalette) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/questionerLogLikelihoods.pdf", 
       width = 2, height=3)
```

Inset

```{r}
modelComparison("questioner_modelComparisonParams")%>% 
  arrange(prob) %>%
  separate(col = modelType, into = c('model', 'saliency')) %>%
  mutate(saliency = ordered(saliency, levels = c('unif', 'emp'), labels = c('uniform', 'empirical'))) %>%
  filter(model != "Q0") %>%
  mutate(model = ordered(model, levels = c('Q1', 'Q2'))) %>%
  ggplot(aes(x = model, y = prob, alpha = saliency, fill = model)) +
    geom_bar(stat = 'identity', position = 'dodge', width = .75) +
    guides(alpha=guide_legend(title="Saliency prior")) +
    ylab('log-likelihood') +
    scale_fill_manual(values = tail(cbPalette, 3)) +
    scale_alpha_manual(values=c(.5, 1)) +
    theme_few(10) +
    coord_cartesian(ylim=c(-350, -300)) +
    theme(legend.position = 'top',
          rect = element_rect(fill = "transparent"), # bg of the panel
          panel.background = element_rect(fill = "transparent",colour = NA),
          plot.background = element_rect(fill = "transparent",colour = NA),
          panel.grid.major = element_blank(), # get rid of major grid
          panel.grid.minor = element_blank(), # get rid of minor grid
          legend.background = element_rect(fill = "transparent",colour = NA),
          legend.box.background = element_rect(fill = "transparent",colour = NA)) # get rid of legend panel bg


ggsave("../writing/2016/journal-manuscript/figures/questionerLogLikelihoodsZoomed.pdf", 
       width = 1.5, height=3)
```
