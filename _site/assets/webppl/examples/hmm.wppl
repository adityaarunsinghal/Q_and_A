/*
Some different representations of the hidden markov model.
 
 All of the below assume that transition is a stochastic transition functions from hidden states to hidden states, and observe is an observation function from hidden to observed states. init is an initial distribution.
*/

var transition = function(s) {return s?flip(0.7):flip(0.3)}

var observe = function(s) {return s?flip(0.9):flip(0.1)}

var init = function() {return flip(0.5)}

var trueobs = [true, true, true]

var arrayEq = function(a, b){
    return a.length == 0 ? true : a[0]==b[0] & arrayEq(a.slice(1), b.slice(1))
}

//this 'direct' version never explicitly represents the partial state sequences.
var hmm1init = function(){var s = init(); return [[s],[observe(s)]]}
var hmm1 = function(n) {
    var prev = (n==1) ? hmm1init() : hmm1(n-1)
    var newstate = transition(prev[0][0])
    var newobs = observe(newstate)
    var next = [ prev[0].concat([newstate]),
                 prev[1].concat([newobs])]
    return next
}

//this version recurses the other way, and passes along the partial state sequences more explicitly
var hmm2_recur = function(n, states, observations){
    var newstate = transition(states[0])
    var newobs = observe(newstate)
    var states = states.concat([newstate])
    var observations = observations.concat([newobs])
    return (n==1) ? [states, observations] : hmm2_recur(n-1,states,observations)
}

var hmm2 = function(n) {
    var s = init()
    return hmm2_recur(n,[s],[observe(s)])
}

var hmm = hmm2

//using any of the versions above, we can condition on some observed states:
Enumerate(function(){
          var r = hmm(2)
          factor( arrayEq(r[1], trueobs) ? 0 : -Infinity )
          return r[0]
          }, 100)

////we could also do inference with a particle filter:
//ParticleFilter(function(){
//          var r = hmm(2)
//          factor( arrayEq(r[1], trueobs) ? 0 : -Infinity )
//          return r[0]
//          }, 500)


/*
 We now explore different ways to optimize inference in the above models.
 
 First we decompose the factor and push the peices up the computation. This gives us a better, more incremental particle filter.
 
 Then we acheive dynamic programming by additionally inserting marginal operators, and chaching them.
 
 */

//first notice that arrayEq will be true if all of a matches the prefix of b, even if it isn't long enough...
//next note that adding factor(s)-factor(s) = factor(s-s) has no effect on the final distribution of the program.
//so we can insert these "intermediate factors":

var hmm_recur = function(n, states, observations){
    var newstate = transition(states[0])
    var newobs = observe(newstate)
    var states = states.concat([newstate])
    var observations = observations.concat([newobs])
    factor(arrayEq(observations, trueobs) ? 0 : -Infinity)
    factor(-(arrayEq(observations, trueobs) ? 0 : -Infinity)) //push this one forward into the next recursion
    return (n==1) ? [states, observations] : hmm_recur(n-1,states,observations)
}

var hmm = function(n) {
    var s = init()
    var observations = [observe(s)]
    factor(arrayEq(observations, trueobs) ? 0 : -Infinity)
    factor(-(arrayEq(observations, trueobs) ? 0 : -Infinity)) //push this one forward into hmm_recur
    return hmm_recur(n,[s],observations)
}

//ParticleFilter(function(){
//               var r = hmm(2)
//               factor( arrayEq(r[1], trueobs) ? 0 : -Infinity )
//               return r[0]
//               }, 100)

//we push the second factor through the return, into the next recursion / function return. this means that the information from the factors accumulates more incrementally as make choices...
//===>
var hmm_recur = function(n, states, observations){
    factor(-(arrayEq(observations, trueobs) ? 0 : -Infinity))
    var newstate = transition(states[0])
    var newobs = observe(newstate)
    var states = states.concat([newstate])
    var observations = observations.concat([newobs])
    factor(arrayEq(observations, trueobs) ? 0 : -Infinity)
    return (n==1) ? [states, observations] : hmm_recur(n-1,states,observations)
}

var hmm = function(n) {
    var s = init()
    var observations = [observe(s)]
    factor(arrayEq(observations, trueobs) ? 0 : -Infinity)
    return hmm_recur(n,[s],observations)
}

//ParticleFilter(function(){
//               var r = hmm(2)
//               //factor(-(arrayEq(r[1], trueobs) ? 0 : -Infinity)) //these now cancel...
//               //factor( arrayEq(r[1], trueobs) ? 0 : -Infinity )
//               return r[0]
//               }, 100)

//finally, if a' = a.slice(0,-1), then arrayEq(a,b) will be false if arrayEq(a',b) is. this allows us to simplify the two factors in this case.
//===>
var hmm_recur = function(n, states, observations){
    var newstate = transition(states[0])
    var newobs = observe(newstate)
    factor( newobs == trueobs[observations.length] ? 0 : -Infinity) //simplify the two factors
    var states = states.concat([newstate])
    var observations = observations.concat([newobs])
    return (n==1) ? [states, observations] : hmm_recur(n-1,states,observations)
}

var hmm = function(n) {
    var s = init()
    var observations = [observe(s)]
    factor(observations[0] == trueobs[0] ? 0 : -Infinity) //simplify since we know that observations is length 1
    return hmm_recur(n,[s],observations)
}

ParticleFilter(function(){
               var r = hmm(2)
               return r[0]
               }, 100)

//fun excercise: use Enumeration with this most recent version that uses intermediate factors and also with the initial "hmm2" above. vary the number of excetutions explore, starting with just 1 and increasing... how do they differ?

//Note: there's one more optimization we'd like to do: we'd like to incorporate the factore when we actually sample newobs, so that we only try observations consistent with trueobs. To do so we need to marginalize out observe(..) (to get an immediate ERP sample) and then use sampleWith Factor(..) to simultaneously sample and incorporate the factor -- we haven't implemented sampleWithFactor yet though.
