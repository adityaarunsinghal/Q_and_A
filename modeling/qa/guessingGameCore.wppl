var foreach = function(lst, fn) {
  var foreach_ = function(i) {
    if (i < lst.length) {
      fn(lst[i]);
      foreach_(i + 1);
    }
  };
  foreach_(0);
};

var questionToNode = dp.cache(function(utterance){
  var temp = qa.butLast(utterance).split("Is");
  var node = temp[1].toLowerCase();
  return node;
});

var locationAssignments = qa.permute([1,2,3,4]);

var taxonomyAnswerMeaning = dp.cache(function(utterance){
  var temp = utterance.split("@");
  var node = temp[0];
  var location = qa.butLast(temp[1]);
  return function(world){
    return world[node] == location; 
  };
});

var isTaxonomyAnswer = dp.cache(function(qudSpace, x){
  return ((last(x) === '.') &
	  (_.includes(qudSpace, qa.butLast(x).split("@")[0])));
});

// our model has two parameters: rationality controls how strongly
// optimizing an agent is; beta controls to what extent participants draw from an
// empirical prior (1) vs. a uniform prior (0) on saliency. 
var QAmodel = function(type, domain, rationality,  beta) {
  var knowledge = qa.buildKnowledge(type, domain);
  var unifTaxonomy = knowledge.unifTaxonomy;
  var empTaxonomy = knowledge.empTaxonomy;
  var qudSpace = knowledge.qudSpace;
  var labelSpace = knowledge.labelSpace;
  
  // To cut down on computational complexity, we fix a location assignment
  var exampleWorld = _.zipObject(qudSpace, [1,2,3,4]);

  var meaning = dp.cache(function(utterance){
    return (isTaxonomyAnswer(qudSpace, utterance) ? taxonomyAnswerMeaning(utterance) :
            utterance === 'null' ? function(w){return true;} :
            console.error('unknown utterance: ' + utterance));
  });

  // Takes a taxonomy object with saliency probabilities
  // and picks one item from each label to be 'the salient one'
  var sampleSalienceAssignment = function() {
    var tax = flip(beta) ? empTaxonomy : unifTaxonomy;
    return mapObject(function(label, probObj) {
      var vals = _.values(probObj);
      var salientItem = categorical(vals, _.keys(probObj));
      return salientItem;
    }, tax);
  };
  
  var worldPrior = function() {
    var locAssignment = uniformDraw(locationAssignments);
    return _.zipObject(qudSpace, locAssignment);
  };

  var questionPrior = function() {
    var v = uniformDraw(labelSpace);
    return 'whereIs' + v.charAt(0).toUpperCase() + v.slice(1) + '?';
  };

  var questionSpace = Infer({method: 'enumerate'}, function(){
    return questionPrior();
  }).support();

  var answerPrior = function(){
    var loc = uniformDraw([1,2,3,4]);
    var leaf = uniformDraw(qudSpace);
    return leaf + '@' + loc + ".";
  };
  
  // returns a function that maps world to the gate we should pick to find
  // a leaf under the given node
  var makeQUD = function(node, tax) {
    return function(world){
      var salientObj = tax ? tax[node] : node;
      return world[salientObj];
    };
  };
  
  var nameToQUD = function(qudName){
    if (_.includes(qudSpace, qudName)) {
      return makeQUD(qudName);
    } else {
      return console.error('unknown qud name', qudName);
    }
  };

  var qudPrior = function() {
    return uniformDraw(qudSpace);
  };
 
  var interpreter = dp.cache(function(answer){
    return Infer({method: 'enumerate'}, function(){
      var world = worldPrior();
      var answerMeaning = meaning(answer);
      condition(answerMeaning(world));
      return world;
    });
  });

  var makeTruthfulAnswerPrior = dp.cache(function(trueWorld) {
    return Infer({method: 'enumerate'}, function(){
      var answer = answerPrior();
      factor(interpreter(answer).score(trueWorld));
      return answer;
    });
  });
	
  var getProjectedWorldPrior = dp.cache(function(qudName) {
    return Infer({method: 'enumerate'}, function(){
      var qud = nameToQUD(qudName);
      return qud(worldPrior());
    });
  });
  
  var literalAnswerer = dp.cache(function(question, trueWorld) {
    return Infer({method: 'enumerate'}, function(){
      var answer = answerPrior();
      factor(interpreter(answer).score(trueWorld) * rationality);
      return answer;
    });
  });
  
  var explicitAnswerer = dp.cache(function(question, trueWorld) {
    var truthfulAnswerPrior = makeTruthfulAnswerPrior(trueWorld);
    return Infer({method: 'enumerate'}, function(){
      var salienceGuess = sampleSalienceAssignment();
      var qud = makeQUD(questionToNode(question), salienceGuess);
      var answer = sample(truthfulAnswerPrior);
      var consistentWorldDist = Infer({method: 'enumerate'}, function(){
	var inferredWorld = sample(interpreter(answer));
	return qud(inferredWorld);
      });
      factor(consistentWorldDist.score(qud(trueWorld)) * rationality);
      return answer;
    });
  });

  var questioner = dp.cache(function(type, qudName) {
    var answerer = function() {(type === 'literal' ? literalAnswerer :
				type === 'explicit' ? explicitAnswerer :
				type === 'pragmatic' ? pragmaticAnswerer :
				console.error('unknown type: ' + type))}();
    return Infer({method: 'enumerate'}, function() {
      var question = questionPrior();
      var informationGainDist = Infer({method: 'enumerate'}, function(){
	var trueWorld = worldPrior();
	var possibleAnswer = sample(answerer(question, trueWorld));

	// compute information gain for this answer, accounting for planning 
	// problem (what would I believe in future if I heard this answer)
	var prior = getProjectedWorldPrior(qudName);
	var posterior = Infer({method: 'enumerate'}, function(){
          var world = worldPrior();
	  observe(answerer(question, world), possibleAnswer);
	  return nameToQUD(qudName)(world);
	});
	return qa.KL(posterior, prior);
      });
      factor(expectation(informationGainDist) * rationality);
      return question;
    });
  });

  var inferQUD = dp.cache(function(question){
    return Infer({method: 'enumerate'}, function() {
      var qudName = qudPrior();
      var q_erp = questioner('explicit', qudName);
      observe(q_erp, question);
      return qudName;
    });
  });

  var pragmaticAnswerer = dp.cache(function(question, trueWorld){
    var qudPosterior = inferQUD(question);
    var truthfulAnswerPrior = makeTruthfulAnswerPrior(trueWorld);
    return Infer({method: 'enumerate'}, function(){
      var qudName = sample(qudPosterior);
      var answer = sample(truthfulAnswerPrior);
      var consistentWorldDist = Infer({method: 'enumerate'}, function(){
	var inferredWorld = sample(interpreter(answer));
	return nameToQUD(qudName)(inferredWorld);
      });
      factor(consistentWorldDist.score(nameToQUD(qudName)(trueWorld)) * rationality);
      return answer;
    });
  });
  
  var runAnswererModel = cache(function(question, coinFlip) {
    // Want to know behavior marginalized across all possible world
    // because of symmetry, we can just use an example world
    var ansERP = (coinFlip ?
		  pragmaticAnswerer(question, exampleWorld) :
		  explicitAnswerer(question, exampleWorld));
    // We marganilize over location information, again because of symmetry
    return Infer({method: 'enumerate'}, function() {
      var ans = sample(ansERP);
      return ans.split("@")[0] + ".";
    });
  });
  
  return {qudSpace : qudSpace,
          questionSpace : questionSpace,
          questioner : questioner,
          pragA : pragmaticAnswerer,
          litA : literalAnswerer,
          expA: explicitAnswerer,
	  runAnswererModel: runAnswererModel,
	 };
};
