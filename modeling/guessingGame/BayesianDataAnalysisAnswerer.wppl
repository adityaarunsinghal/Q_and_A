// Run as:
// webppl BayesianDataAnalysisAnswerer.wppl --require ../qa

var questionToLabel = function(question) {
  return qa.butLast(question).split("Is")[1].toLowerCase();
};

// Condition on data, jointly infer two params:
// 1. alpha, a global rationality param
// 2. beta, which interpolates between the emp prior and uniform prior
//
// might eventually want to have a questioner that reasons about BOTH
// the explicit and pragmatic answerers, and weights them so we can
// infer that weight
var inferParams = function() {
  var data = qa.readCSV("../../MultiExperiment2/data/"
			+ "MultiExp2_BayesianAnalysisInput.csv");
  qa.writeCSV([["alpha", "beta", "type", "domain",
		"utterance", "response", "modelProb"]], "BayesianPragAnswererSupp.csv");
  qa.writeCSV([["alpha", "beta"]], "BayesianPragAnswererResults.json");
  var types = ["branching", "overlapping", "equivocal"];
  var domains = ["artifact", "animals", "places", "plants"];

  var outputERP = MCMC(function(){
    var alpha = uniform(0,20);
    var beta = uniform(0,1);

    var items = qa.cartesianProductOf([types, domains]);

    var score = sum(map(function(item) {
      var model = QAmodel(item[0], item[1], alpha, beta);
      var runAnswererModel = model.runAnswererModel;
      var pragA = model.pragA;
      return sum(map(function(question) {
	var itemData = qa.getSubset(data, {type:item[0], domain: item[1],
					   question:questionToLabel(question)});
	var pragERP = runAnswererModel(pragA, question);
	var score = sum(map(function(dataRow) {
	  var localScore = pragERP.score([], dataRow[5] + ".");
	  return localScore;
	}, itemData));
	qa.writeERP(pragERP, [alpha, beta, item[0], item[1], questionToLabel(question)],
		    "BayesianPragAnswererSupp.csv", 10);
	return score;
      }, model.questionSpace));
    }, items));
    factor(score);
    return [alpha, beta];
  }, {samples: 1000, verbose: true});
  outputERP.print();
  qa.writeERP(outputERP, [], "BayesianPragAnswererResults.json");
};

inferParams();
