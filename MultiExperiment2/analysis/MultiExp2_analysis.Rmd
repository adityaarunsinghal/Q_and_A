---
title: "MultiExp2_analysis"
output: html_document
---

Set wd

```{r}
library(knitr)
opts_knit$set(root.dir = '/Users/rxdh/Box Sync/stanford/research/goodman/q&a/MultiExperiment2/')
setwd("/Users/rxdh/Box Sync/stanford/research/goodman/q&a/MultiExperiment2/")
library(tidyr)
library(plyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
#library(MultinomialCI)
library(boot)
```

Experiment data analysis
--------------------------

Load data, pull in game ids from the mturk info dump

```{r}
ps = read.csv("./data/MultiExp2_compiled-subject_information.csv",
              sep = ',', header = TRUE)
mturk = read.csv("./data/MultiExp2_compiled-mturk.csv",
                 sep=',', header= TRUE) %>%
  mutate(gameID = Answer.id) %>%
  select(workerid, gameID)
d = read.csv("./data/MultiExp2_compiled-trials_clean.csv",  
             sep = ',', header = TRUE) %>%
  right_join(mturk, by = 'workerid')
```

Filter out participants who didn't complete all 12 trials or didn't list english as their native language, then get rid of duplicate games

```{r}
english_ps <- (ps %>% 
               filter(nativeEnglish == "yes"))$workerid
cat("We removed", length(ps$workerid) - length(english_ps), "ps due to language")
#trialsCompleted = d %>% count(workerid) %>% mutate(numCompleted = n)
filteredD = d %>% filter(workerid %in% english_ps) %>% 
       filter(answer != "NA") 
completedGames = (filteredD %>% group_by(gameID) %>% 
                    count(gameID) %>% mutate(numCompleted = n) %>% 
                    filter(numCompleted == 24))$gameID
cat("We removed", length(unique(d$workerid)) - length(completedGames)*2, "games total")
d <- filteredD %>% filter(gameID %in% completedGames) %>% 
     distinct(domain, goal, question, guess, answer, type, gameID)
write.csv(d, file = "./data/MultiExp2_BayesianAnalysisInput.csv",
          row.names = F)
```

In order to compare different items in a convenient way, we're going to map the questions and answers to the corresponding node positions in the hierarchy. So, in 'branching' trials, for example, 'dalmatian', 'mansion', 'carrot', and 'couch' would all be treated the same.


```{r}
source("~/Box Sync/stanford/research/goodman/q&a/MultiExperiment2/analysis/analysisHelpers.R")
d <- mapWordsToNodes(d)
```

We're also going to estimate empirical probabilities for each response, conditioned on the domain, type, and goal of the trial. To get confidence intervals for these estimates, we'll use the bootstrap. Tidy up questioner data...

```{r}
d_q = d %>% 
      mutate(response=ordered(questionNodes, levels=c("Q1","Q2","Q3","Q4"))) %>%
      mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
      group_by(domain, type, goal) %>%
      do(getProbs(data = ., QorA = 'q')) %>%
      select(goal, type, response, domain, count,
             groupSize, empProb) %>%
      ungroup() %>%
      mutate(domain = factor(domain),
             type = factor(type),
             goal = ordered(goal, levels=c("G1","G2","G3","G4")))

```

Tidy up answerer data...

```{r}
d_a = d %>% 
      mutate(response=ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
      mutate(utterance=ordered(questionNodes,levels=c("Q1","Q2","Q3","Q4"))) %>%
      group_by(domain, type, utterance) %>%
      do(getProbs(data = ., QorA = 'a')) %>%
      select(utterance, type, response, domain, count,
             groupSize, empProb) %>%
      ungroup() %>%
      mutate(domain = factor(domain),
             type = factor(type),
             utterance = ordered(utterance, levels=c("Q1","Q2","Q3","Q4")))
```

How well do the different domains correlate?
----------------------

```{r}
col1 = subset(d_q, domain == "animals")$empProb
col2 = subset(d_q, domain == "places")$empProb
col3 = subset(d_q, domain == "plants")$empProb
col4 = subset(d_q, domain == "artifact")$empProb
corData_q = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cor(corData_q)

col1 = subset(d_a, domain == "animals")$empProb
col2 = subset(d_a, domain == "places")$empProb
col3 = subset(d_a, domain == "plants")$empProb
col4 = subset(d_a, domain == "artifact")$empProb
corData_a = data.frame(animal = col1, place = col2, plant = col3, artifact = col4)
cor(corData_a)
```

Chi-squared tests
-----------------

Questioners first:

```{r}
overall_distribution = (d_q %>% group_by(goal, type, response) %>% summarize(count = sum(count)))
overall_distribution
test_G1_q = chisq.test(subset(overall_distribution, 
                              goal == "G1" & type == "branching")$count) 
test_G1_q
test_G2_q = chisq.test(subset(overall_distribution, 
                              goal == "G2"& type == "branching")$count)
test_G2_q
test_G3_q = chisq.test(subset(overall_distribution, 
                              goal == "G3"& type == "branching")$count)
test_G3_q
test_G4_q = chisq.test(subset(overall_distribution, 
                              goal == "G4"& type == "branching")$count)
test_G4_q

# Equivocal
test_G1_q = chisq.test(subset(overall_distribution, 
                              goal == "G1" & type == "equivocal" 
                              & (response %in% c("Q1", "Q2")))$count)
test_G1_q
test_G4_q = chisq.test(subset(overall_distribution, 
                              goal == "G4" & type == "equivocal" 
                              & (response %in% c("Q1", "Q2")))$count)
test_G4_q
# Examine domain-level effects
(d_q %>% 
   group_by(goal, domain, type, response) %>% 
   summarize(count = sum(count)) %>% 
   filter(type == "equivocal" 
          & goal %in% c("G2", "G3") 
          & response %in% c("Q1", "Q2")) %>% 
   group_by(domain, response) %>% 
   summarize(count = sum(count)))

chisq.test(subset(overall_distribution, 
                              goal == "G1" & type == "overlapping")$count) 
chisq.test(subset(overall_distribution, 
                              goal == "G2"& type == "overlapping")$count)
chisq.test(subset(overall_distribution, 
                              goal == "G3"& type == "overlapping")$count)
chisq.test(subset(overall_distribution, 
                              goal == "G4"& type == "overlapping")$count)
```

Now for answerers:

```{r}
overall_distribution = (d_a %>% group_by(utterance, type, response) %>% summarize(count = sum(count)))
overall_distribution
chisq.test(subset(overall_distribution, 
                  utterance == "Q1"& type == "branching")$count) 
chisq.test(subset(overall_distribution, 
                  utterance == "Q2"& type == "branching")$count)
chisq.test(subset(overall_distribution, 
                  utterance == "Q3"& type == "branching")$count)
chisq.test(subset(overall_distribution, 
                  utterance == "Q4"& type == "branching")$count)

# Equivocal
chisq.test(subset(overall_distribution, 
                  utterance == "Q1" & type == "equivocal")$count)
chisq.test(subset(overall_distribution, 
                  utterance == "Q2" & type == "equivocal")$count)
# Examine domain-level effects
(d_q %>% 
   group_by(goal, domain, type, response) %>% 
   summarize(count = sum(count)) %>% 
   filter(type == "equivocal" 
          & goal %in% c("G2", "G3") 
          & response %in% c("Q1", "Q2")) %>% 
   group_by(domain, response) %>% 
   summarize(count = sum(count)))

chisq.test(subset(overall_distribution, 
                  utterance == "Q1"& type == "overlapping")$count) 
chisq.test(subset(overall_distribution, 
                  utterance == "Q2"& type == "overlapping")$count)
chisq.test(subset(overall_distribution, 
                  utterance == "Q3"& type == "overlapping")$count)
chisq.test(subset(overall_distribution, 
                  utterance == "Q4"& type == "overlapping")$count)

```
Fitting rationality parameters
------------------------------

First, we define this function that takes a data frame and computes which parameter values optimize the correlation between model and data. Now we import the answer fits and tidy them up to eventually be joined

```{r}
# Have to vectorize these operations: for loop takes ages
vectorizedMapAnswer <- Vectorize(mapAnswer);
vectorizedMapQuestion <- Vectorize(mapQuestion);
answerModelOutput=read.csv("../modeling/guessingGame/answererPredictionsUnif.csv", 
                            sep = ',') %>% 
  mutate(question = as.character(utterance), 
         answer = as.character(response)) %>%
  do(mutate(., answer = vectorizedMapAnswer(type, answer))) %>%
  do(mutate(., question = vectorizedMapQuestion(type, question))) %>%
  mutate(utterance = as.factor(question), response = as.factor(answer)) %>% 
  select(type, domain, modelLevel, utterance, rationality, response, modelProb)

ansFits = optimalFit(inner_join(d_a, answerModelOutput)) %>%
  select(domain, modelLevel, type, utterance, 
         response, empProb, rationality, modelProb)
```

Now that each of these data sets is in a nice format, we can join them all together and plot their fits:

```{r}
# join them all together
all_ans = d_a %>% 
  inner_join(ansFits, by = c('domain', 'type', 'utterance', 'response', 'empProb')) %>%
#  group_by(type, modelLevel, utterance, response, modelProb, rationality) %>%
#  summarise(meanEmpProb = mean(emp_prob)) %>%
#  ungroup() %>%
  mutate(modelLevel = ordered(modelLevel, 
                               levels = c("literal", "explicit", "pragmatic"))) %>%
  select(type, domain, utterance, response, empProb, modelLevel, modelProb) 
  #distinct(utterance, response, model_level, model_prob)

# Since they won't let us annotate nicely...
  
labelDataFrame = all_ans %>% 
   group_by(modelLevel) %>% 
   summarise(correlation = paste("r =", round(cor(empProb, 
                                                  modelProb, method = 'pearson'), 2)))

pdf(file="../writing/2015/journal-manuscript/figures/Exp2UnifPriorAnsFits.pdf",
     width = 7, height = 3)

answer_plots = (ggplot(all_ans, aes(x = modelProb, y = empProb))
  + theme(text = element_text(size = 20),
          axis.text.x = element_text(angle=90, vjust=1))
  + xlab("Model predicted probability")
  + ylim(0,1)
  + ylab("Empirical Probability")
  + geom_point(aes(colour = domain, shape = type))
  + geom_abline(intercept = 0, slope = 1, linetype = "dotted")
  + scale_x_continuous(lim = c(0,1), breaks=c(0,.5,1))
  + ggtitle("Answerer Model Fits")
  + geom_smooth(method = "lm")
  + facet_grid( ~ modelLevel)
  + geom_text(aes(x,y,label=lab),
              data=data.frame(x = .75, y = .25,
                              modelLevel = labelDataFrame$modelLevel,
                              lab = labelDataFrame$correlation))
  + theme_bw())
answer_plots         
dev.off()
```

Now we import the questioner fits and tidy them up to eventually be joined

```{r}
vectorizedMapGoal <- Vectorize(mapGoal);

questionModelOutput=read.csv("../modeling/guessingGame/questionerPredictionsUnif.csv", sep = ',') %>%
  mutate(goal = as.character(goal),
         question = as.character(response)) %>%
  do(mutate(., goal = vectorizedMapGoal(type, goal))) %>%
  do(mutate(., question = vectorizedMapQuestion(type, question))) %>%
  mutate(goal = as.factor(goal), response = as.factor(question)) %>% 
  select(type, domain, modelLevel, goal, rationality, response, modelProb)

         
questFits = optimalFit(inner_join(d_q, questionModelOutput)) %>%
  select(type, domain, modelLevel, goal, response, empProb, modelProb)
```

Now make the questioner plot

```{r}
# join them all together
all_qs = d_q %>% 
  inner_join(questFits, by = c('type', 'domain', 'goal', 'response', 'empProb')) %>%
  mutate(modelLevel = ordered(modelLevel, 
                               levels = c("literal", "explicit", "pragmatic"))) %>%
  select(type, domain, goal, response, empProb, modelLevel, modelProb) 
  #distinct(type, domain, goal, response, modelLevel, modelProb)

# Since they won't let us annotate nicely...
  
labelDataFrame = all_qs %>% 
   group_by(modelLevel) %>% 
   summarise(correlation = paste("r =", round(cor(empProb, 
                                                  modelProb, method = 'pearson'), 2)))

pdf(file="../writing/2015/journal-manuscript/figures/Exp2UnifPriorQuestFits.pdf",
     width = 7, height = 3)
question_plots = (ggplot(all_qs, aes(x = modelProb, y = empProb))
  + theme(text = element_text(size = 20),
          axis.text.x = element_text(angle=90, vjust=1))
#          axis.text.x = element_blank(), axis.ticks = element_blank())
#          plot.margin=unit(c(1,1,-1,1), "cm"))
  + ylim(0,1)
  + xlab("Model Predicted Probability")
  + ylab("Empirical Probability")
  + geom_point(aes(colour = domain, shape = type))
  + ggtitle("Questioner Model Fits")
  + geom_abline(intercept = 0, slope = 1, linetype = "dotted")
  + geom_smooth(method = "lm")
  + facet_grid( ~ modelLevel)
  + geom_text(aes(x,y,label=lab),
              data=data.frame(x = .75, y = .25,
                              modelLevel = labelDataFrame$modelLevel,
                              lab = labelDataFrame$correlation))
  + theme_bw())
question_plots               
dev.off()
```

Test whether one fit is significantly better than another fit

```{r}
library(cocor)
empSet = subset(all_ans, modelLevel == "pragmatic")$empProb
expSet = subset(all_ans, modelLevel == "explicit")$modelProb
pragSet = subset(all_ans, modelLevel == "pragmatic")$modelProb
cocor(~ empirical + expModel | empirical + pragModel, data.frame(empirical = empSet, expModel = expSet, pragModel = pragSet))

empSet = subset(all_qs, modelLevel == "pragmatic")$empProb
expSet = subset(all_qs, modelLevel == "explicit")$modelProb
pragSet = subset(all_qs, modelLevel == "pragmatic")$modelProb
cocor(~ empirical + expModel | empirical + pragModel, data.frame(empirical = empSet, expModel = expSet, pragModel = pragSet))

```

Model + data bar plots
----------------------

Plot for pragmatic questioner. These bar graphs will help show what our model is getting right and what it's getting wrong.

```{r}
# first, average over domains
collapsed_q <- d %>% 
    mutate(response = ordered(questionNodes, levels = c("Q1","Q2","Q3","Q4"))) %>%
    mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
    group_by(type, goal) %>%
    do(getProbsAndCIs(data = ., QorA = 'q', R = 1000)) %>%
    mutate(empirical = empProb) %>%
    select(goal, type, response, count, lower_ci, upper_ci,
           groupSize, empirical)

pragModelPreds = questFits %>% 
  group_by(goal, type, modelLevel, response) %>% 
  summarize(model = mean(modelProb)) %>% 
  filter(modelLevel == "pragmatic")

plottableQ = collapsed_q %>% inner_join(pragModelPreds, by = c('goal', 'type', 'response')) %>%
  select(goal, type, response, empirical, model, lower_ci, upper_ci) %>%
  gather(src, prob, empirical, model) %>% 
  do(mutate(., lower_ci = ifelse(src == "model", NA, lower_ci))) %>%
  do(mutate(., upper_ci = ifelse(src == "model", NA, upper_ci)))

pdf('../writing/2015/journal-manuscript/figures/exp2QuestResults.pdf',
    width = 8, height=4)
dodge <- position_dodge(width=0.9)
g <- (ggplot(plottableQ, aes(x = response, y = prob, fill = src))
      + geom_bar(position = dodge, stat = "identity") 
      + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                      position = dodge, width = .25)
      + facet_grid(type ~ goal)
      + ggtitle("Pragmatic Questioner")
      + theme_bw())
g
dev.off()

```

Answerer predictions + empirical data

```{r}
# first, average over domains
collapsed_a <- d %>% 
    mutate(response = ordered(answerNodes,levels=c("A1","A2","A3","A4"))) %>%
    mutate(utterance = ordered(questionNodes,levels = c("Q1","Q2","Q3","Q4"))) %>%
    group_by(type, utterance) %>%
    do(getProbsAndCIs(data = ., QorA = 'a', R = 1000)) %>%
    mutate(empirical = empProb) %>%
    select(utterance, type, response, count, lower_ci, upper_ci,
           groupSize, empirical)

pragModelPreds = ansFits %>% 
  group_by(utterance, type, modelLevel, response) %>% 
  summarize(model = mean(modelProb)) %>% 
  filter(modelLevel == "pragmatic")

plottableA = collapsed_a %>% 
  inner_join(pragModelPreds, by = c('utterance','type','response')) %>%
  select(utterance, type, response, empirical, model, lower_ci, upper_ci) %>%
  gather(src, prob, empirical, model) %>% 
  do(mutate(., lower_ci = ifelse(src == "model", NA, lower_ci))) %>%
  do(mutate(., upper_ci = ifelse(src == "model", NA, upper_ci)))

pdf('../writing/2015/journal-manuscript/figures/exp2AnsResults.pdf',
    width = 8, height=4)

dodge <- position_dodge(width=0.9)
g <- (ggplot(plottableA, aes(x = response, y = prob, fill = src))
      + geom_bar(position = dodge, stat = "identity") 
      + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                      position = dodge, width = .25)
      + facet_grid(type ~ utterance)
      + ggtitle("Pragmatic Answerer")
      + theme_bw())
g
dev.off()
```

zoom in on overlapping condition

```{r}
collapsed_q <- d %>% 
    mutate(response = ordered(questionNodes, levels = c("Q1","Q2","Q3","Q4"))) %>%
    mutate(goal = ordered(goalNodes, levels = c("G1", "G2", "G3", "G4"))) %>%
    group_by(goal,type) %>%
    filter(type == "overlapping") %>%
    filter(domain != "places") %>%
    do(getProbsAndCIs(data = ., QorA = 'q', R = 1000)) %>%
    mutate(empirical = empProb) %>%
    select(goal, type, response, count, lower_ci, upper_ci, 
           groupSize, empirical)

pragModelPreds = questFits %>% 
  filter(domain != "places") %>%
  group_by(goal, type, modelLevel, response) %>% 
  summarize(pragmaticModel = mean(modelProb)) %>% 
  filter(modelLevel == "pragmatic")

expModelPreds = questFits %>% 
  filter(domain != "places") %>%
  group_by(goal, type, modelLevel, response) %>% 
  summarize(explicitModel = mean(modelProb)) %>% 
  filter(modelLevel == "explicit")

plottableQ = collapsed_q %>% 
  inner_join(pragModelPreds, by = c('goal', 'type', 'response')) %>%
  inner_join(expModelPreds, by = c('goal', 'type', 'response')) %>%
  select(goal, type, response, lower_ci, upper_ci, groupSize,
         empirical, pragmaticModel, explicitModel) %>%
  gather(src, prob, empirical, pragmaticModel, explicitModel) %>%
  filter(goal == "G2") %>%
  do(mutate(., lower_ci = ifelse(src %in% c("pragmaticModel", "explicitModel"), 
                                 NA, lower_ci))) %>%
  do(mutate(., upper_ci = ifelse(src %in% c("pragmaticModel", "explicitModel"),
                                 NA, upper_ci)))

#png(filename = "../writing/2015/fyp-report/OverlappingModelComparison.png",
#     width = 2000, height=1000,res = 300, pointsize = 16)

(ggplot(plottableQ, aes(x = response, y = prob, fill = src))
 + geom_bar(position = dodge, stat= 'identity')
 + geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                 position = dodge, width =.25)
 + geom_hline(yintercept = 0.48)
 + ggtitle("Overlapping model comparison")
 + theme_bw()
 + scale_fill_manual(values = c("#B2DF8A", "#A6CEE3", "#62A0CA")))
# dev.off()
```

