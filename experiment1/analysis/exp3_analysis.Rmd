---
title: "exp3_analysis"
output: html_document
---

Set wd

```{r}
setwd("/Users/rxdh/Box Sync/stanford/research/goodman/q&a/experiment1/")
library(tidyr)
library(plyr)
library(dplyr)
library(ggplot2)
```

Experiment data analysis
--------------------------

Load and clean data. We remove people who self-identify as 'confused' 

```{r}
d = read.csv("versions/experiment1_short/data/q_and_a3_short-trials.tsv",  sep = '\t')
# Remove people who were confused...
ps = read.csv("versions/experiment1_short/data/q_and_a3_short-subject_information.tsv", 
              sep = '\t')
# we only want to exclude people who specifically recorded that they were confused,
# keeping people who just left the response box blank.
nonconfused_ps <- (ps %>% 
                   mutate(asses2 = ifelse(is.na(asses), "None", asses)) %>% 
                   filter(asses2 != 1))$workerid 
d = filter(d, workerid %in% nonconfused_ps)
```

Tidy up questioner data...

```{r}
d_q = d %>% 
      filter(trial_type == 'question') %>%
      mutate(response = ordered(response, levels = c("dalmatian", "dog", 
                                                     "mammal", "animal"))) %>%
      mutate(utterance = ordered(qud, levels = c("dalmatian", "poodle", 
                                                 "siamese cat", "goldfish"))) %>%
      group_by(qud) %>%
      mutate(group_size = n()) %>%
      group_by(qud, response) %>% # collapse over participants
      summarize(emp_prob = (n() / mean(group_size))) %>% # compute empirical probabilities
      select(qud, response, emp_prob)

# Hadley Wickham hasn't fixed summarize to take drop = F yet, so we have to re-insert rows with p = 0
d_q = d_q %>%
      right_join(expand.grid(response  = levels(d_q$response),
                             qud = levels(d_q$qud))) %>%
      mutate(emp_prob = ifelse(is.na(emp_prob), 0, emp_prob)) %>%
      mutate(qud_label = paste("qud:", qud)) %>%
      mutate(qud_label = ordered(qud_label, 
                                 levels = c("qud: dalmatian", "qud: poodle",
                                            "qud: siamese cat", "qud: goldfish"))) 
```

Tidy up answerer data...

```{r}
d_a = d %>% 
      filter(trial_type == 'ans:') %>%
      filter(response != "None") %>%
      mutate(response = as.numeric(response)) %>%
      mutate(response = as.character(mapply(function(str, num) strsplit(str,",")[[1]][num], 
                                    as.character(world_state), response))) %>%
      mutate(response = ordered(response,
                                levels=c("dalmatian","poodle","siamese cat","goldfish"))) %>%
      mutate(utterance = ordered(utterance,
                                 levels = c("dalmatian", "dog", "mammal", "animal"))) %>%
      group_by(utterance) %>%
      mutate(group_size = n()) %>%
      group_by(utterance, response) %>% # collapse over participants
      summarize(emp_prob = (n() / mean(group_size))) %>% # compute empirical probabilities
      select(utterance, response, emp_prob)

# Hadley Wickham hasn't fixed summarize to take drop = F yet, so we have to re-insert rows with p = 0
d_a = d_a %>% 
      right_join(expand.grid(response  = levels(d_a$response),
                             utterance = levels(d_a$utterance))) %>%
      mutate(emp_prob = ifelse(is.na(emp_prob), 0, emp_prob)) %>%
      mutate(utterance_label = paste("utterance:", utterance)) %>%
      mutate(utterance_label = ordered(utterance_label,
                                       levels = c("utterance: dalmatian","utterance: dog", 
                                                  "utterance: mammal","utterance: animal")))
```

Fitting rationality parameters
------------------------------

First, we define this function that takes a data frame and computes which parameter values optimize the correlation between model and data.

```{r}
# Expect two columns that end with _prob (i.e. emp_prob and model_prob)
optimalFit <- function(data) {
  prob_correlation <- data %>%
    group_by(answerR, questionR) %>%
    filter(answerR > 1) %>%
    summarise(correlation = cor(model_prob, emp_prob))
  max_val_data = prob_correlation[which.max(prob_correlation$correlation),]
  print(max_val_data)
  return = data %>%
    filter(answerR == max_val_data$answerR, questionR == max_val_data$questionR)  
}
```

Now we import the literal answer fits and tidy them up to eventually be joined
```{r}
lit_ans_fits = join(d_a,read.csv("analysis/model_prediction/litAnswererRationalityFitting.csv", sep = ',')) %>%
  mutate(model_prob = jitter(model_prob)) %>%
  mutate(answerR = ansR) %>% # This looks sketchy, but we know that these parameters don't matter...
  mutate(questionR = ansR) %>%
  select(utterance, response, utterance_label, emp_prob, answerR, questionR, model_prob)
lit_ans_fits = optimalFit(lit_ans_fits) %>%
  mutate(lit_cor = cor(emp_prob, model_prob)) %>%
  rename(lit_ansR = answerR, lit_qR = questionR, lit_prob = model_prob)
```

Next we import the explicit answer fits and tidy them up

```{r}
exp_ans_fits = optimalFit(join(d_a, 
                          read.csv("analysis/model_prediction/expAnswererRationalityFitting.csv", 
                                    sep =','))) %>%
  mutate(explicit_cor = cor(emp_prob, model_prob)) %>%
  rename(explicit_ansR = answerR, explicit_qR = questionR, explicit_prob = model_prob) 
```

Finally, we import the pragmatic answer fits and tidy them up

```{r}
prag_ans_fits = optimalFit(join(d_a, 
                          read.csv("analysis/model_prediction/pragAnswererRationalityFitting.csv", 
                                   sep =','))) %>% 
  mutate(pragmatic_cor = cor(emp_prob, model_prob)) %>%
  rename(pragmatic_ansR = answerR, pragmatic_qR = questionR, pragmatic_prob = model_prob) 
```

Now that each of these data sets is in a nice format, we can join them all together and plot their fits:

```{r}
# join them all together
all_ans = d_a %>% 
  join(lit_ans_fits) %>% 
  join(exp_ans_fits) %>% 
  join(prag_ans_fits) %>%
  gather(condition.1, model_prob, 
         explicit_prob, pragmatic_prob, lit_prob) %>%
  separate(condition.1, c("model_level", "type")) %>%
  mutate(model_level = ordered(model_level, 
                               levels = c("lit", "explicit", "pragmatic"))) %>%
  select(utterance, response, emp_prob, utterance_label, 
         model_level, model_prob) 
  #distinct(utterance, response, model_level, model_prob)

# Since they won't let us annotate nicely...
  
jpeg(filename="../writing/2015/cogsci/answererFits.jpeg")
answer_plots = (ggplot(all_ans, aes(x = model_prob, y = emp_prob))
  + theme(text = element_text(size = 20),
          axis.text.x = element_text(angle=90, vjust=1))
  + geom_point()
  + geom_abline(intercept = 0, slope = 1, linetype = "dotted")
  + scale_x_continuous(lim = c(0,1), breaks=seq(0, 1.1, 0.5))
  + geom_smooth(method = "lm")
  + facet_wrap(~ model_level)
  + geom_text(aes(x,y,label=lab),
              data=data.frame(x = .75, y = .25,
                              model_level = levels(all_ans$model_level),
                              lab = (all_ans %>% 
                                       group_by(model_level) %>% 
                                       summarise(correlation = paste("r =",  round(cor(emp_prob, model_prob), 2))))$correlation)))
answer_plots               
dev.off()
```

Fit (very dumb) literal questioner parameters 

```{r}
d_lit_q <- tbl_df(d) %>%  # start with empirical data
  filter(trial_type == 'question') %>%
  select(workerid, qud, response) %>%
       group_by(qud, response) %>% # collapse over participants
       summarise(emp_prob = n() / 23) %>% # compute empirical probabilities
       right_join(expand.grid(response=levels(d_q$response), # append back on
                             qud = levels(d_q$qud))) %>%
       join(read.csv("analysis/model_prediction/litQuestionerRationalityFitting.csv",
                           sep = ',')) # join with model predictions
       
d_lit_q[is.na(d_lit_q)] <- 0

d_lit_q_correlation <- d_lit_q %>% 
  group_by(ansR, KLR) %>% 
  filter(ansR > 1) %>% # corr < 0 for ansR <= 1, which throws off scale
  summarise(correlation = cor(jitter(model_prob), jitter(emp_prob)))

max_val_lit_q = d_lit_q_correlation[which.max(d_lit_q_correlation$correlation),]
best_pred_lit_q = subset(d_lit_q, ansR == max_val_lit_q$ansR & KLR == max_val_lit_q$KLR)

# Plot best model
jpeg(filename="../writing/2015/cogsci/bestLitQuestioner.jpeg")
g_bestlit_q <- (ggplot(best_pred_lit_q, aes(x = model_prob, y = emp_prob))
            + theme(text = element_text(size=20))              
            + geom_point() 
            + ggtitle("Literal Questioner Fit")
            + geom_abline(intercept = 0, slope = 1, linetype="dotted")
            + xlim(0:1)
            + geom_smooth(method = "lm"))
g_bestlit_q
dev.off()
```

Fit explicit answerer parameters

```{r}
d_exp_a <- tbl_df(d_a) %>%  # start with empirical data
       select(workerid, utterance, response) %>%
       group_by(utterance, response) %>% # collapse over participants
       summarise(emp_prob = n() / 23) %>% # compute empirical probabilities
       right_join(expand.grid(response  = levels(d_a$response),
                              utterance = levels(d_a$utterance))) %>%
       join(read.csv("analysis/model_prediction/expAnswererRationalityFitting.csv", 
                     sep =','))
d_exp_a[is.na(d_exp_a)] <- 0

exp_a_correlation <- d_exp_a %>% 
  group_by(ansR) %>% 
  filter(ansR > 1) %>% # corr < 0 for ansR <= 1, which throws off scale
  summarise(correlation = cor(model_prob, emp_prob))

max_val_exp_a = exp_a_correlation[which.max(exp_a_correlation$correlation),]
best_pred_exp_a = subset(d_exp_a, ansR == max_val_exp_a$ansR)

# Plot best model
jpeg(filename="../writing/2015/cogsci/bestExpAnswerer.jpeg")
g_bestA <- (ggplot(best_pred_exp_a, aes(x = model_prob, y = emp_prob))
            + theme(text = element_text(size=20))      
            + geom_point() 
            + ggtitle("Explicit Answerer Fit")
            + geom_abline(intercept = 0, slope = 1, linetype="dotted")
            + annotate("text", x = .25, y = .75, size = 10,
                       label = paste("r = ", round(max_val_exp_a$correlation,2)))
            + geom_smooth(method = "lm")
            + xlim(0:1))
g_bestA
dev.off()
```

Fit explicit questioner parameters 

```{r}
d_exp_q <- tbl_df(d_q) %>%  # start with empirical data
       group_by(qud, response) %>% # collapse over participants
       summarise(emp_prob = n() / 23) %>% # compute empirical probabilities
       right_join(expand.grid(response=levels(d_q$response), # append back on
                             qud = levels(d_q$qud))) %>%
       join(read.csv("analysis/model_prediction/expQuestionerRationalityFitting.csv",
                           sep = ',')) # join with model predictions
       
d_exp_q[is.na(d_exp_q)] <- 0

d_exp_q_correlation <- d_exp_q %>% 
  group_by(ansR, KLR) %>% 
  filter(ansR > 1) %>% # corr < 0 for ansR <= 1, which throws off scale
  summarise(correlation = cor(model_prob, emp_prob))

max_val_exp_q = d_exp_q_correlation[which.max(d_exp_q_correlation$correlation),]
best_pred_exp_q = subset(d_exp_q, ansR == max_val_exp_q$ansR & KLR == max_val_exp_q$KLR)

# Plot param space
g_exp_qParams <- (ggplot(d_exp_q_correlation, aes(x = ansR, y =KLR))
       + geom_tile(aes(fill = correlation))
       + geom_point(x = max_val_exp_q$ansR, y = max_val_exp_q$KLR, 
                    color = 'white', size = 5)
       + scale_fill_gradient(low = "white", high = "black"))
g_exp_qParams

# Plot best model
jpeg(filename="../writing/2015/cogsci/bestExpQuestioner.jpeg")
g_bestexp_q <- (ggplot(best_pred_exp_q, aes(x = model_prob, y = emp_prob))
            + theme(text = element_text(size=20))                
            + geom_point() 
            + ggtitle("Explicit Questioner Fit")
            + geom_abline(intercept = 0, slope = 1, linetype="dotted")
            + xlim(0:1)
            + annotate("text", x = .25, y = .75, size = 10,
                       label = paste("r = ", round(max_val_exp_q$correlation,2)))
            + geom_smooth(method = "lm"))
g_bestexp_q
dev.off()
```

Fit pragmatic answerer parameters

```{r}
d_prag_a <- tbl_df(d_a) %>%  # start with empirical data
       select(workerid, utterance, response) %>%
       group_by(utterance, response) %>% # collapse over participants
       summarise(emp_prob = n() / 23) %>% # compute empirical probabilities
       right_join(expand.grid(response  = levels(d_a$response),
                              utterance = levels(d_a$utterance))) %>%
       join(read.csv("analysis/model_prediction/pragAnswererRationalityFitting.csv", 
                     sep =','))
d_prag_a[is.na(d_prag_a)] <- 0


prag_a_correlation <- d_prag_a %>% 
  group_by(ansR, KLR, qudR, pragR) %>% 
  filter(ansR > 1) %>% # corr < 0 for ansR <= 1, which throws off scale
  summarise(correlation = cor(model_prob, emp_prob))

max_val_prag_a = prag_a_correlation[which.max(prag_a_correlation$correlation),]
best_pred_prag_a = subset(d_prag_a, ansR == max_val_prag_a$ansR 
                          & KLR == max_val_prag_a$KLR 
                          & qudR == max_val_prag_a$qudR 
                          & pragR == max_val_prag_a$pragR)

# Plot param space
g_aParams <- (ggplot(prag_a_correlation, aes(x = ansR, y =KLR))
       + geom_tile(aes(fill = correlation))
       + geom_point(x = max_val_prag_a$ansR, y = max_val_prag_a$KLR, 
                    color = 'white', size = 5)
       + scale_fill_gradient(low = "white", high = "black"))
g_aParams

# Plot best model
jpeg(filename="../writing/2015/cogsci/bestPragAnswerer.jpeg")
g_bestA <- (ggplot(best_pred_prag_a, aes(x = model_prob, y = emp_prob))
            + theme(text = element_text(size=20))
            + geom_point() 
            + ggtitle("Pragmatic Answerer Fit")
            + geom_abline(intercept = 0, slope = 1, linetype="dotted")
            + xlim(0:1)
            + annotate("text", x = .25, y = .75, size = 10,
                       label = paste("r = ", round(max_val_prag_a$correlation,2)))
            + geom_smooth(method = "lm"))
g_bestA
dev.off()
```

Fit pragmatic questioner (reasoning about pragmatic answerer)

```{r}
d_prag_q <- tbl_df(d_q) %>%  # start with empirical data
       group_by(qud, response) %>% # collapse over participants
       summarise(emp_prob = n() / 23) %>% # compute empirical probabilities
       right_join(expand.grid(response=levels(d_q$response), # append back on
                             qud = levels(d_q$qud))) %>%
       join(read.csv("analysis/model_prediction/pragQuestionerRationalityFitting.csv",
                           sep = ',')) # join with model predictions
       
d_prag_q[is.na(d_prag_q)] <- 0

d_prag_q_correlation <- d_prag_q %>% 
  group_by(rPragKL) %>% 
  filter(rPragKL > 1) %>% # corr < 0 for ansR <= 1, which throws off scale
  summarise(correlation = cor(model_prob, emp_prob))

max_val_prag_q = d_prag_q_correlation[which.max(d_prag_q_correlation$correlation),]
best_pred_prag_q = subset(d_prag_q, rPragKL == max_val_prag_q$rPragKL)

# Plot best model
jpeg(filename="../writing/2015/cogsci/bestPragQuestioner.jpeg")
g_bestprag_q <- (ggplot(best_pred_prag_q, aes(x = model_prob, y = emp_prob))
            + theme(text = element_text(size=20))        
            + geom_point() 
            + ggtitle("Pragmatic Questioner Fit")
            + geom_abline(intercept = 0, slope = 1, linetype="dotted")
            + xlim(0:1)
            + annotate("text", x = .25, y = .75, size = 10,
                       label = paste("r = ", round(max_val_prag_q$correlation,2)))
            + geom_smooth(method = "lm"))
g_bestprag_q
dev.off()
```

Model + data bar plots
----------------------

Plot for pragmatic questioner. These bar graphs will help show what our model is getting right and what it's getting wrong.

```{r}
best_pred_prag_q = subset(d_prag_q, rPragKL == max_val_prag_q$rPragKL)
best_pred_prag_q$response = ordered(best_pred_prag_q$response, 
                          levels = c("dalmatian", "dog","mammal", "animal"))
new_labels = sapply(X = best_pred_prag_q$qud, FUN = function(v) {return(paste("qud:", v))})
best_pred_prag_q$facet_label = ordered(new_labels,
                             levels = c("qud: dalmatian", "qud: poodle", 
                                        "qud: siamese cat", "qud: goldfish"))
q_comparison <- best_pred_prag_q %>% 
  select(qud, response, emp_prob, model_prob, facet_label) %>%
  rename(empirical = emp_prob, model = model_prob) %>%
  gather(src, prob, empirical, model) 

jpeg(filename="../writing/2015/cogsci/questionerDataComparison.jpeg")
g4<-(ggplot(q_comparison, aes(x=response, y=prob, fill=src)) 
    #+ scale_y_continuous(limits = c(0,.3))
    + geom_bar(stat='identity', position=position_dodge())
    + theme_bw(base_size = 20)
    + theme(axis.text.x = element_text(angle=90, vjust=1))
    + ggtitle("(a) Best Questioner Model Predictions")
    + facet_wrap(~facet_label))
g4
dev.off()
```

Now, plot for dumb model:

```{r}
best_pred_prag_a = subset(d_prag_a, ansR == max_val_prag_a$ansR 
                          & KLR == max_val_prag_a$KLR 
                          & qudR == max_val_prag_a$qudR 
                          & pragR == max_val_prag_a$pragR)
best_pred_prag_a$response = ordered(best_pred_prag_a$response, 
                                    levels = c("dalmatian", "poodle", 
                                               "siamese cat", "goldfish"))
new_labels = as.factor(sapply(X = best_pred_prag_a$utterance, FUN = function(v) {return(paste("utterance:", v))}))
best_pred_prag_a$facet_label = ordered(new_labels, 
                              levels = c("utterance: dalmatian", "utterance: dog", 
                                         "utterance: mammal","utterance: animal"))
a_comparison <- best_pred_prag_a %>% 
  select(utterance, response, emp_prob, model_prob, facet_label) %>%
  rename(empirical = emp_prob, model = model_prob) %>%
  gather(src, prob, empirical, model) 

jpeg(filename="../writing/2015/cogsci/answererDataComparison.jpeg")
g4<-(ggplot(a_comparison, aes(x=response, y = prob, fill=src)) 
     + geom_bar(stat='identity', position=position_dodge())
     + theme_bw(base_size = 20)
     + theme(axis.text.x = element_text(angle=90, vjust=1))
     + ggtitle("(b) Best Answerer Model Predictions")
     + facet_wrap(~facet_label))
g4
dev.off()
```
